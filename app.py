import streamlit as st
import google.generativeai as genai


# 1. API í‚¤ ì„¤ì • (Google AI Studioì—ì„œ ë°œê¸‰ë°›ì€ í‚¤ ì…ë ¥)
GOOGLE_API_KEY = "AIzaSyBbYUnSBp32fVzTiTlVRcN1GE9JK2BrLKs"
genai.configure(api_key=GOOGLE_API_KEY)

# 2. FAQ ë°ì´í„° ì •ì˜ (ì—¬ê¸°ì— ì¤€ë¹„í•˜ì‹  FAQ ë‚´ìš©ì„ ììœ ë¡­ê²Œ ë„£ìœ¼ì„¸ìš”)
faq_data = """
[ë¡œë³´ì–´ë“œë°”ì´ì € FAQ]
Q: ë¡œë³´ì–´ë“œë°”ì´ì € ì„œë¹„ìŠ¤ë€ ë¬´ì—‡ì¸ê°€ìš”?
A: AI ì•Œê³ ë¦¬ì¦˜ì´ ê³ ê°ì˜ íˆ¬ì ì„±í–¥ì— ë§ì¶° í¬íŠ¸í´ë¦¬ì˜¤ë¥¼ ìë™ìœ¼ë¡œ êµ¬ì„±í•˜ê³  ê´€ë¦¬í•´ì£¼ëŠ” ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤.

Q: ê°€ì… ìµœì†Œ ê¸ˆì•¡ì€ ì–¼ë§ˆì¸ê°€ìš”?
A: ìƒí’ˆë³„ë¡œ ë‹¤ë¥´ì§€ë§Œ, ë³´í†µ 10ë§Œ ì›ë¶€í„° ì‹œì‘ ê°€ëŠ¥í•©ë‹ˆë‹¤.

Q: ìˆ˜ìˆ˜ë£ŒëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?
A: ì—°ê°„ ìš´ìš©ë³´ìˆ˜ëŠ” ì•½ 0.5% ë‚´ì™¸ì´ë©°, ë§¤ë§¤ ìˆ˜ìˆ˜ë£ŒëŠ” ë³„ë„ì…ë‹ˆë‹¤.
(ì—¬ê¸°ì— ë” ë§ì€ FAQ ë‚´ìš©ì„ ê³„ì† ì¶”ê°€í•˜ì„¸ìš”...)
"""

# 3. ëª¨ë¸ ì„¤ì • (Gemini 3 Flash ì‚¬ìš©)
# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì— FAQ ë°ì´í„°ë¥¼ ì£¼ì…í•©ë‹ˆë‹¤.
system_prompt = f"""
ë‹¹ì‹ ì€ 'ë¡œë³´ì–´ë“œë°”ì´ì €' ì „ìš© ê³ ê°ìƒë‹´ AIì…ë‹ˆë‹¤.
ë°˜ë“œì‹œ ì•„ë˜ ì œê³µëœ [FAQ ë°ì´í„°]ë¥¼ ë°”íƒ•ìœ¼ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”.
ë°ì´í„°ì— ì—†ëŠ” ë‚´ìš©ì´ë¼ë©´ "ì£„ì†¡í•©ë‹ˆë‹¤. í•´ë‹¹ ë‚´ìš©ì€ ê³ ê°ì„¼í„°(1588-XXXX)ë¡œ ë¬¸ì˜ ë¶€íƒë“œë¦½ë‹ˆë‹¤"ë¼ê³  ë‹µë³€í•˜ì„¸ìš”.

[FAQ ë°ì´í„°]
{faq_data}
"""

model = genai.GenerativeModel(
    model_name="gemini-3-flash-preview",
    system_instruction=system_prompt
)

# 4. ì›¹ í™”ë©´ UI êµ¬ì„± (Streamlit)
st.set_page_config(page_title="ë¯¸ë˜ì—ì…‹ ë¡œë³´ ì±—ë´‡", page_icon="ğŸ¤–")
st.title("ğŸ¤– ë¯¸ë˜ì—ì…‹ ë¡œë³´ì–´ë“œë°”ì´ì € ìƒë‹´")
st.caption("FAQ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ AIê°€ ë‹µë³€í•´ ë“œë¦½ë‹ˆë‹¤.")

if "messages" not in st.session_state:
    st.session_state.messages = []

# ê¸°ì¡´ ëŒ€í™” ê¸°ë¡ í‘œì‹œ
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ì‚¬ìš©ì ì§ˆë¬¸ ì…ë ¥
if prompt := st.chat_input("ê¶ê¸ˆí•œ ì ì„ ì…ë ¥í•˜ì„¸ìš”"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # AI ë‹µë³€ ìƒì„±
    with st.chat_message("assistant"):
        response = model.generate_content(prompt)
        st.markdown(response.text)
        st.session_state.messages.append({"role": "assistant", "content": response.text})
