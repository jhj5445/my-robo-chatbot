import streamlit as st
import google.generativeai as genai
import ssl
import requests
import warnings

# -----------------------------------------------------------------------------
# SSL Fix for FinanceDataReader & KRX (User Environment Specific)
# -----------------------------------------------------------------------------
try:
    _create_unverified_https_context = ssl._create_unverified_context
except AttributeError:
    pass
else:
    ssl._create_default_https_context = _create_unverified_https_context

# Requests Verify Patch
from requests.packages.urllib3.exceptions import InsecureRequestWarning
warnings.simplefilter('ignore', InsecureRequestWarning)

# Monkey-patch requests to disable verification by default
if not hasattr(requests, '_original_get'):
    requests._original_get = requests.get
    requests._original_post = requests.post

    def new_get(*args, **kwargs):
        kwargs['verify'] = False
        return requests._original_get(*args, **kwargs)

    def new_post(*args, **kwargs):
        kwargs['verify'] = False
        return requests._original_post(*args, **kwargs)

    requests.get = new_get
    requests.post = new_post
# -----------------------------------------------------------------------------

import os
import glob
import re
import streamlit.components.v1 as components
import yfinance as yf
import plotly.express as px
import pandas as pd
from sklearn.linear_model import LinearRegression
from sklearn.svm import SVR
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error
import lightgbm as lgb
import numpy as np
import numpy as np
import scipy.optimize as sco
from pykrx import stock
import time
from datetime import datetime, timedelta


# 1. API í‚¤ ì„¤ì • (Google AI Studioì—ì„œ ë°œê¸‰ë°›ì€ í‚¤ ì…ë ¥)
# ì•ˆì „í•œ ë°©ì‹ (Streamlit Secrets ì‚¬ìš©)
# -----------------------------------------------------------------------------
# 1. API í‚¤ ì„¤ì • (Rotation Logic)
# -----------------------------------------------------------------------------
# ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“  API í‚¤ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
api_keys = []

# 1. Streamlit Secrets ìš°ì„  í™•ì¸
if "GOOGLE_API_KEY" in st.secrets:
    api_keys.append(st.secrets["GOOGLE_API_KEY"])
    # ì¶”ê°€ í‚¤ í™•ì¸ (GOOGLE_API_KEY_2, _3 ...)
    i = 2
    while f"GOOGLE_API_KEY_{i}" in st.secrets:
        api_keys.append(st.secrets[f"GOOGLE_API_KEY_{i}"])
        i += 1
else:
    # 2. í™˜ê²½ ë³€ìˆ˜ í™•ì¸ (ë¡œì»¬ í…ŒìŠ¤íŠ¸)
    key = os.getenv("GOOGLE_API_KEY")
    if key:
        api_keys.append(key)
        # ì¶”ê°€ í‚¤ í™•ì¸
        i = 2
        while os.getenv(f"GOOGLE_API_KEY_{i}"):
            api_keys.append(os.getenv(f"GOOGLE_API_KEY_{i}"))
            i += 1

if not api_keys:
    st.error("API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .streamlit/secrets.toml ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.stop()

# ê¸°ë³¸ í‚¤ë¡œ ì´ˆê¸° ì„¤ì •
genai.configure(api_key=api_keys[0])

def generate_content_with_rotation(prompt, model_name="gemini-3-flash-preview"):
    """
    API í‚¤ë¥¼ ìˆœí™˜í•˜ë©° ì»¨í…ì¸  ìƒì„±ì„ ì‹œë„í•©ë‹ˆë‹¤.
    Rate Limit ë°œìƒ ì‹œ ë‹¤ìŒ í‚¤ë¡œ ìë™ ì „í™˜í•©ë‹ˆë‹¤.
    """
    last_error = None
    
    for i, key in enumerate(api_keys):
        try:
            # í˜„ì¬ í‚¤ë¡œ ì„¤ì • ë° ìƒì„± ì‹œë„
            genai.configure(api_key=key)
            model = genai.GenerativeModel(model_name)
            response = model.generate_content(prompt)
            return response.text
            
        except Exception as e:
            last_error = e
            # Quota ê´€ë ¨ ì—ëŸ¬ì¸ ê²½ìš° ë‹¤ìŒ í‚¤ ì‹œë„
            # (429 Resource exhausted, Quota exceeded ë“±)
            error_str = str(e)
            if "429" in error_str or "Quota" in error_str or "Resource exhausted" in error_str:
                # ë§ˆì§€ë§‰ í‚¤ê°€ ì•„ë‹ˆë©´ ë‹¤ìŒ í‚¤ë¡œ ê³„ì†
                if i < len(api_keys) - 1:
                    continue
            
            # ê·¸ ì™¸ ì—ëŸ¬ê±°ë‚˜ ë§ˆì§€ë§‰ í‚¤ë©´ ë£¨í”„ ì¢…ë£Œ (After loop raises)
            break
            
    # ëª¨ë“  ì‹œë„ ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ë°œìƒ
    raise last_error

# -----------------------------------------------------------------------------

# 2. FAQ ë°ì´í„° ì •ì˜ (ì—¬ê¸°ì— ì¤€ë¹„í•˜ì‹  FAQ ë‚´ìš©ì„ ììœ ë¡­ê²Œ ë„£ìœ¼ì„¸ìš”)
faq_data = """
[ë¡œë³´ì–´ë“œë°”ì´ì € ì„œë¹„ìŠ¤ ìƒì„¸ ë§¤ë‰´ì–¼]

### 1. ì„œë¹„ìŠ¤ ê¸°ëŠ¥ ë° ê¸°ë³¸ ì›ì¹™
- **ê°€ì… ë° ì„¤ê³„**: ê°€ì…ê³¼ ë™ì‹œì— ë§ì¶¤ì„¤ê³„ê°€ ì§„í–‰ë˜ëŠ” ê²ƒì´ ì•„ë‹ˆë©°, ê³ ê°ì´ ê°€ì… í›„ ì§ì ‘ ë§ì¶¤ì„¤ê³„ë¥¼ ì§„í–‰í•´ì•¼ í•©ë‹ˆë‹¤. ì´ëŠ” ê³ ê°ì—ê²Œ í¬íŠ¸í´ë¦¬ì˜¤ë¥¼ 'ì¶”ì²œ'ë“œë¦¬ëŠ” ì„œë¹„ìŠ¤ì´ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.
- **íˆ¬ìì„±í–¥**: íˆ¬ììì„±í–¥ê³¼ ìƒê´€ì—†ì´ ê°€ì…ì€ ê°€ëŠ¥í•˜ë©°, ìµœì¢…ì—ëŠ” ë³¸ì¸ íˆ¬ìì„±í–¥ì— ë”°ë¥¸ í¬íŠ¸í´ë¦¬ì˜¤ ìœ í˜•ì´ ì„ íƒë˜ì§€ë§Œ íƒ€ ìœ í˜•ë„ ì„ íƒ ê°€ëŠ¥í•©ë‹ˆë‹¤. ë‹¨, ë§ì¶¤ì„¤ê³„ ê³¼ì •ì—ì„œ íˆ¬ìë¶€ì í•©ì„± ì•ˆë‚´, ì•½ê´€ë™ì˜ ë“± í•„ìˆ˜ ê³ ì§€ì‚¬í•­ í”„ë¡œì„¸ìŠ¤ê°€ ì¶”ê°€ ë°œìƒí•©ë‹ˆë‹¤.
- **í¬íŠ¸í´ë¦¬ì˜¤ ë¹„ì¤‘ ìˆ˜ì •**: íˆ¬ììê°€ ì„ì˜ë¡œ ìì‚°êµ° ë¹„ì¤‘ì„ ìˆ˜ì •í•˜ê±°ë‚˜ ì¼ë¶€ í€ë“œë§Œ êµì²´í•˜ê²Œ ì„¤ì •í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í‡´ì§ì—°ê¸ˆì˜ ìœ„í—˜ìì‚°ë¹„ìœ¨ ì¤€ìˆ˜ë¥¼ ìœ„í•´ ë¡œë³´ì–´ë“œë°”ì´ì €ê°€ ë§¤ë§¤ ì‹œ ìë™ìœ¼ë¡œ ë¹„ì¤‘ ì¤€ìˆ˜ë¥¼ ìœ„í•œ ë§¤ë§¤ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤.
- **í€ë“œ êµì²´ ë²”ìœ„**: ì›ì¹™ì ìœ¼ë¡œ ê³ ê°ì´ ê°€ì§€ê³  ê³„ì‹  ê³µëª¨í€ë“œ ì „ì²´ê°€ êµì²´ ëŒ€ìƒì…ë‹ˆë‹¤. ë‹¨, ë¡œë³´ì–´ë“œë°”ì´ì €ê°€ íŒë‹¨í•˜ê¸°ì— 1ìœ„ ìƒí’ˆê³¼ ì„±ëŠ¥ì´ ìœ ì‚¬í•œ í€ë“œëŠ” ì¼ë¶€ë§Œ ë§¤ë§¤ë  ìˆ˜ ìˆìœ¼ë©°, ê±°ë˜ ë²”ì£¼ì—ì„œ ì œì™¸ë˜ëŠ” í•­ëª©ì€ ë§¤ë§¤ì—ì„œ ì œì™¸ë©ë‹ˆë‹¤.

### 2. ê°€ì… ë¶ˆê°€ ìš”ê±´ ìƒì„¸ (ê° ê³„ì¢Œë³„)
- **í‡´ì§ì—°ê¸ˆ**: MPêµ¬ë… ì„œë¹„ìŠ¤ ì´ìš© ê³„ì¢Œ ë“±.
- **ê°œì¸ì—°ê¸ˆ**: ì—°ê¸ˆê°œì‹œ ì •ê¸°ì§€ê¸‰ ê³„ì¢Œ(ì„ì˜ì‹ì€ ê°€ëŠ¥), ëŒ€ì¶œ ì•½ì •ê³„ì¢Œ, ì—°ê¸ˆì €ì¶•ê³„ì¢Œ ì •ê¸°ë§¤ë„ ì•½ì •ê³„ì¢Œ, ìë™ëŒ€ì²´ì…ê¸ˆë§¤ìˆ˜ ì•½ì •ê³„ì¢Œ, CMSìë™ëŒ€ì²´ì…ê¸ˆë§¤ìˆ˜ ì•½ì •ê³„ì¢Œ, í€ë“œ ì •ê¸°ìë™ë§¤ìˆ˜ ì•½ì •ê³„ì¢Œ, ì´ì „ìš© ê³„ì¢Œ, ì´ê´€ì‹ ì²­ì¤‘ ê³„ì¢Œ, ì‚¬ê³ ê³„ì¢Œ(ë§¤ë§¤ì œí•œ) ë° ì¥ê¸°ë¯¸ì‚¬ìš© ê³„ì¢Œ. íƒ€ ì„œë¹„ìŠ¤ ì´ìš© ì¤‘ì¸ ê²½ìš°(ê°œì¸ì—°ê¸ˆ ë©, ê°œì¸ì—°ê¸ˆ ìë¬¸, ì ë¦½ì‹ ìë™ë§¤ìˆ˜ ì„œë¹„ìŠ¤-ì—°ê¸ˆ ëª¨ìœ¼ê¸°) ê°€ì… ë¶ˆê°€.
- **ISA**: ê³„ì¢Œí•´ì§€ ì‹ ì²­ì¤‘ ë° ì´í›„ë‹¨ê³„ ê³„ì¢Œ, ìë™ëŒ€ì²´ì…ê¸ˆë§¤ìˆ˜ ì•½ì •ê³„ì¢Œ, CMSìë™ëŒ€ì²´ì…ê¸ˆë§¤ìˆ˜ ì•½ì •ê³„ì¢Œ, í€ë“œ ì •ê¸°ìë™ë§¤ìˆ˜ ì•½ì •ê³„ì¢Œ, ì‚¬ê³ ê³„ì¢Œ(ë§¤ë§¤ì œí•œ), ì ë¦½ì‹ ìë™ë§¤ìˆ˜ ì„œë¹„ìŠ¤, ì´ê´€ì‹ ì²­ì ‘ìˆ˜/ì´ê´€í•´ì§€ì‹ ì²­ ê³„ì¢Œ, ë§Œê¸°ì´ˆê³¼ ê³„ì¢Œ.
- **ì¼ë°˜ê³„ì¢Œ**: ê³„ì¢Œí•´ì§€ ì‹ ì²­ì¤‘ ë° ì´í›„ë‹¨ê³„ ê³„ì¢Œ, ìë™ëŒ€ì²´ì…ê¸ˆë§¤ìˆ˜ ì•½ì •ê³„ì¢Œ, CMSìë™ëŒ€ì²´ì…ê¸ˆë§¤ìˆ˜ ì•½ì •ê³„ì¢Œ, ì‚¬ê³ ê³„ì¢Œ(ë§¤ë§¤ì œí•œ), ì ë¦½ì‹ ìë™ë§¤ìˆ˜ ì„œë¹„ìŠ¤, ì´ê´€ì‹ ì²­ì ‘ìˆ˜/ì´ê´€í•´ì§€ì‹ ì²­ ê³„ì¢Œ, ë§Œê¸°ì´ˆê³¼ ê³„ì¢Œ, ì‹ ìš©/ëŒ€ì¶œ/ëŒ€ì—¬/ì œíœ´ ì•½ì •ê³„ì¢Œ, ê³µëª¨ë¶€ë™ì‚°ë¶„ë¦¬ê³¼ì„¸ ì•½ì •, ë¶„ë¦¬ê³¼ì„¸í•˜ì´ì¼ë“œ ì•½ì •, ë¶„ë¦¬ê³¼ì„¸ê³ ìœ„í—˜ê³ ìˆ˜ìµí€ë“œ ì•½ì •, ì›”ì§€ê¸‰ ì•½ì •, ê³„ì¢Œì¦ê±°ê¸ˆë¥  100% ì™¸, í•´ì™¸ì£¼ì‹ ê³„ì¢Œì¦ê±°ê¸ˆë¥  100% ì™¸, ê³„ì¢Œìœ„íƒì¦ê±°ê¸ˆ ë¯¸ì§•ìˆ˜, ë§¤ë§¤í—ˆìš© ìœ ê°€ì¦ê¶Œ 'í€ë“œ' ë¯¸ë“±ë¡ ê³„ì¢Œ. ë©ê³„ì•½ ì•½ì •ê³„ì¢Œ, ìë¬¸ì‚¬ ì¼ì„/ìë¬¸ ê³„ì¢Œ ì´ìš© ì‹œ ë¶ˆê°€.
- **ë¹„ê³¼ì„¸ì¢…í•©ì €ì¶•**: ìœ„ ì¼ë°˜ê³„ì¢Œ ìš”ê±´ê³¼ ë™ì¼í•¨.

### 3. ë§ì¶¤ì„¤ê³„ ì´ìš© ì œí•œ ì—¬ë¶€ ë° ì œì™¸ ìƒí’ˆ (MAPIS ê¸°ì¤€)
- **ì •ìƒ ìƒíƒœ ê¸°ì¤€ (MAPIS 7895, 8525)**: 
  * íˆ¬ììì„±í–¥: ì„±ì¥í˜•, ì„±ì¥ì¶”êµ¬í˜• ë“± (ì•ˆì •ì¶”êµ¬í˜• ë“± ë¶€ì í•© ì‹œ 'í•´ë‹¹'ìœ¼ë¡œ í‘œì‹œë¨)
  * íˆ¬ìê¶Œìœ : 'í¬ë§' ìƒíƒœì—¬ì•¼ í•¨
  * ìš´ìš©ê°€ëŠ¥ê¸ˆì•¡: 10,000ì› ì´ìƒ
  * ìœ„í—˜ìì‚°ë¹„ìœ¨: í‡´ì§ì—°ê¸ˆì˜ ê²½ìš° 70% ì´í•˜
  * ë³´ìœ ìƒí’ˆê°¯ìˆ˜: í‡´ì§ì—°ê¸ˆ 20ê°œ ë¯¸ë§Œ, ê°œì¸ì—°ê¸ˆ/ISA ë“± 50ê°œ ì´í•˜
- **ìš´ìš© ë° í‰ê°€ ì œì™¸ í€ë“œ ë¦¬ìŠ¤íŠ¸**: ì•„ë˜ í€ë“œëŠ” í€ë“œí‰ê°€ê¸ˆì•¡ ë° ìš´ìš©ê°€ëŠ¥ê¸ˆì•¡ ì§‘ê³„ì—ì„œ ì œì™¸ë©ë‹ˆë‹¤.
  1) ê±°ë˜ë¶ˆê°€í€ë“œ (ì˜ˆ: ëŸ¬ì‹œì•„ í€ë“œ ë“±)
  2) í™˜ë§¤ìˆ˜ìˆ˜ë£Œ ë°œìƒ í€ë“œ
  3) ì‚¬ëª¨í€ë“œ
  4) ì˜¤í”„ë¼ì¸ì „ìš©í€ë“œ
  5) í™˜ë§¤ê¸ˆì§€í€ë“œ
  6) ì„±ê³¼ë³´ìˆ˜ í€ë“œ
  7) ì½”ìŠ¤ë‹¥ë²¤ì²˜ í€ë“œ
  8) ìˆ™ë ¤ëŒ€ìƒ í€ë“œ

### 4. 2026/1/1 ìµœì‹  ì œí•œ ë° ì—…ë°ì´íŠ¸ ì‚¬í•­
- **í˜„ì¬ìê¸ˆíˆ¬ìì„±í–¥ ì œí•œ**: Q1 'ë‹¨ê¸° ìƒê³„ ìê¸ˆ' í˜¹ì€ Q2 'ì›ê¸ˆ ë³´ì¡´ ì¶”êµ¬' ë‹µë³€ ì¤‘ í•˜ë‚˜ë¼ë„ ì²´í¬ëœ ê²½ìš° ì´ìš© ë¶ˆê°€. (MAPIS 3250ì—ì„œ í™•ì¸ ë° ì¬ì§„ë‹¨ í•„ìš”)
- **ISA í•´ì§€ ê´€ë ¨**: ISA ë¶€ì í•© ìš”ê±´ ë°œìƒ í˜¹ì€ ê³„ì¢Œ ì´ì „ ì‹ ì²­ ì‹œ, í•´ë‹¹ ê³„ì¢Œì˜ ë¡œë³´ì–´ë“œë°”ì´ì € ê°€ì…ì„ ì‚¬ì „ì ìœ¼ë¡œ í•´ì§€í•´ì•¼ ì—…ë¬´ ì§„í–‰ì´ ê°€ëŠ¥í•¨.
- **íˆ¬ìì„¤ëª…ì„œ ë°œì†¡ (25/10/24 ì¶”ê°€)**:
  * í‡´ì§ì—°ê¸ˆ: ë§ì¶¤ì„¤ê³„ ì™„ë£Œ ì§í›„ 1íšŒë§Œ ì•Œë¦¼í†¡ ë°œì†¡.
  * ê°œì¸ì—°ê¸ˆ/ISA/ì¼ë°˜: ë§¤ìˆ˜ë˜ëŠ” í€ë“œë§ˆë‹¤ ë§¤ìˆ˜ ì‹œì ì— ê°œë³„ íˆ¬ìì„¤ëª…ì„œ ë°œì†¡.

### 5. ë§¤ë§¤, ìˆ˜ìµë¥  ë° ì•Œë¦¼ ê·œì¹™
- **ë§¤ë§¤ ë¶ˆê°€ ì‹œê°„**: 23ì‹œ 55ë¶„ ~ 24ì‹œ 05ë¶„ (ì£¼ë¬¸ ì œì¶œ ì‹œ ì‹¤íŒ¨ ë° ì „ì²´ ì·¨ì†Œ ì²˜ë¦¬).
- **ë¦¬ë°¸ëŸ°ì‹± ì•Œë¦¼**: ìˆ˜ì‹œ(ì§ì „ ìŠ¹ì¸ 5ì˜ì—…ì¼ ê²½ê³¼ ë° ë¹„ì¤‘ ì°¨ì´ ë°œìƒ ì‹œ, ì•½ 14ì¼ ì£¼ê¸° ê²€ì¶œ), ì •ê¸°(ìµœì¢… ìŠ¹ì¸ í›„ 40ì˜ì—…ì¼ ê²½ê³¼ ì‹œ).
- **ìˆ˜ìµë¥  í™•ì¸ ë¶ˆê°€ ì‚¬ìœ **: ê³„ì¢Œ ë‚´ ë¡œë³´ ë¯¸ìš´ìš© ìƒí’ˆ(ì˜ˆê¸ˆ, ELB, ETF ë“±) ì¡´ì¬ë¡œ ì¸í•œ í˜¼ë™ ë°©ì§€ ë° ê³ ê° ì˜ì‚¬(ìŠ¹ì¸/ê±°ì ˆ) ê°œì…ì— ë”°ë¥¸ ì„±ê³¼ ì°¨ì´ ë•Œë¬¸.
- **ì„±ê³¼ í™•ì¸ ê²½ë¡œ**: [MY ë¡œë³´ì–´ë“œë°”ì´ì € > ê³„ì¢Œí˜„í™© > ë³´ìœ í€ë“œ] ë˜ëŠ” [MY í€ë“œ] í™”ë©´.

### 6. ì£¼ìš” ì—ëŸ¬ ì‚¬ë¡€ (Error Case)
1) **ì†Œìˆ˜ì  ì²˜ë¦¬**: í‡´ì§ì—°ê¸ˆì—ì„œ ì•„ì£¼ ì ì€ ê¸ˆì•¡ íˆ¬ì ì‹œ ë¹„ì¤‘ ë‹¨ìœ„ê°€ ì •ìˆ˜ì´ê¸° ë•Œë¬¸ì— 'ë§¤ë„ ìƒí’ˆ ì—†ìŒ' ì—ëŸ¬ ë°œìƒ ê°€ëŠ¥.
2) **ìœ„í—˜ìì‚° ë¹„ì¤‘ ì‹œì°¨**: ë‹¹ì¼ ë§¤ë§¤ë¡œ ìœ„í—˜ìì‚°ë¹„ìœ¨ 70% ì´ˆê³¼ ìƒíƒœì—ì„œ ì„¤ê³„ ì‹œ ì¥ì•  ë°œìƒ. ê²°ì œ ì™„ë£Œ ì‹œê¹Œì§€ ëŒ€ê¸° í•„ìš”.
3) **ì¤‘ë³µ í”„ë¡œì„¸ìŠ¤**: 'í¬íŠ¸í´ë¦¬ì˜¤ ë³€ê²½ì´ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤' íŒì—… ì‹œ ê¸°ì¡´ ë§¤ë§¤ ìŠ¤ì¼€ì¤„ ì·¨ì†Œ í›„ ì¬ì§„í–‰.
4) **ë¯¸êµ­ êµ­ì ì**: ë§¤ë§¤ ë¶ˆê°€ í€ë“œ í¬í•¨ ì‹œ ë§ì¶¤ì„¤ê³„ ë‹¨ê³„ì—ì„œ ì—ëŸ¬.
5) **í‡´ì‚¬ í›„ DC ê³„ì¢Œ**: ê°€ì…ì ë²ˆí˜¸ê°€ ë‚¨ì•„ í™”ë©´ ì§„ì…ì€ ê°€ëŠ¥í•˜ë‚˜ ì„¤ê³„ ì‹œ ì—ëŸ¬ ë°œìƒ (ì°¨ì„¸ëŒ€ ì´í›„ ìˆ˜ì • ì˜ˆì •).
"""

# 3. ëª¨ë¸ ì„¤ì • (Gemini 3 Flash ì‚¬ìš©)
# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì— FAQ ë°ì´í„°ë¥¼ ì£¼ì…í•©ë‹ˆë‹¤.
system_prompt = f"""
ë‹µë³€ì˜ 1ìˆœìœ„ ê·¼ê±°ëŠ” ì œê³µëœ **[FAQ ë°ì´í„°]**ì…ë‹ˆë‹¤.
ë§Œì•½ FAQì— ì—†ëŠ” ë‚´ìš© ì¤‘ ì¼ë°˜ì ì¸ ê¸ˆìœµ ì§€ì‹ì€ ë‹¹ì‹ ì˜ ê¸°ë³¸ ì§€ì‹ì„ í™œìš©í•´ ì„¤ëª…í•˜ë˜, ë¯¸ë˜ì—ì…‹ì˜ êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ë‚˜ ì •ì±…ì€ ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”.
ë¯¼ê°í•œ íˆ¬ì ê¶Œìœ  ì§ˆë¬¸ì—ëŠ” FAQì˜ ê³µì‹ ì…ì¥ì„ ì „ë‹¬í•˜ì„¸ìš”.
ì¼ë°˜ì ì¸ ì§€ì‹ì´ ì•„ë‹ˆê³ , [FAQ ë°ì´í„°]ì— ì—†ëŠ” ë‚´ìš©ì´ë¼ë©´ "ì£„ì†¡í•©ë‹ˆë‹¤. í•´ë‹¹ ë‚´ìš©ì€ ê³ ê°ì„¼í„°(1588-XXXX)ë¡œ ë¬¸ì˜ ë¶€íƒë“œë¦½ë‹ˆë‹¤"ë¼ê³  ë‹µë³€í•˜ì„¸ìš”."
[FAQ ë°ì´í„°]
{faq_data}
"""

model = genai.GenerativeModel(
    model_name="gemini-3-flash-preview",
    system_instruction=system_prompt
)

# 4. ì›¹ í™”ë©´ UI êµ¬ì„± (Streamlit)
st.set_page_config(page_title="ë¡œë³´ì–´ë“œë°”ì´ì € ì±—ë´‡", page_icon="ğŸ¤–", layout="wide")

# OP.GG ìŠ¤íƒ€ì¼ ì»¤ìŠ¤í…€ CSS ì ìš© (Light Theme)
st.markdown(
    """
    <style>
        /* ê¸°ë³¸ í°íŠ¸ ì„¤ì • */
        @import url('https://fonts.googleapis.com/css2?family=Noto+Sans+KR:wght@300;400;500;700&display=swap');
        
        html, body, [class*="css"] {
            font-family: 'Noto Sans KR', sans-serif;
        }

        /* ë©”ì¸ ë°°ê²½ìƒ‰ - OP.GGì˜ ë°ì€ íšŒìƒ‰/ë¸”ë£¨ í†¤ */
        .stApp {
            background-color: #ecf2f5;
            color: #23292f; /* ì§™ì€ íšŒìƒ‰ í…ìŠ¤íŠ¸ */
        }

        /* ì‚¬ì´ë“œë°” ë°°ê²½ìƒ‰ - OP.GGì˜ ì§™ì€ ë„¤ì´ë¹„ (í—¤ë” ëŠë‚Œ) */
        [data-testid="stSidebar"] {
            background-color: #1c2836;
        }
        
        /* ì‚¬ì´ë“œë°” ë‚´ í…ìŠ¤íŠ¸ ìƒ‰ìƒ ì¡°ì • (ë” êµ¬ì²´ì ìœ¼ë¡œ) */
        [data-testid="stSidebar"] h1, [data-testid="stSidebar"] h2, [data-testid="stSidebar"] h3, [data-testid="stSidebar"] label, [data-testid="stSidebar"] p {
            color: #ffffff !important;
        }

        /* ë¼ë””ì˜¤ ë²„íŠ¼ ìŠ¤íƒ€ì¼ ì»¤ìŠ¤í…€ (ì‚¬ì´ë“œë°” ë©”ë‰´) */
        [data-testid="stSidebar"] [data-testid="stRadio"] label {
            background-color: transparent;
            color: #b0b8c1 !important; /* ê¸°ë³¸: íšŒìƒ‰ */
            padding: 10px;
            border-radius: 4px;
            transition: all 0.2s;
            margin-bottom: 2px;
            cursor: pointer;
        }
        
        /* ë¼ë””ì˜¤ ë²„íŠ¼ ì„ íƒëœ í•­ëª© */
        [data-testid="stSidebar"] [data-testid="stRadio"] label[data-checked="true"] {
             background-color: #5383e8 !important; /* ì„ íƒì‹œ ë¸”ë£¨ ë°°ê²½ */
             color: #ffffff !important; /* ì„ íƒì‹œ í°ê¸€ì”¨ */
             font-weight: bold;
        }
        
        /* ë¼ë””ì˜¤ ë²„íŠ¼ í˜¸ë²„ íš¨ê³¼ */
        [data-testid="stSidebar"] [data-testid="stRadio"] label:hover {
             background-color: #24354a; /* í˜¸ë²„ì‹œ ì•½ê°„ ë°ì€ ë„¤ì´ë¹„ */
             color: #ffffff !important;
        }

        /* í—¤ë” ë°°ê²½ìƒ‰ */
        [data-testid="stHeader"] {
            background-color: rgba(0,0,0,0);
        }

        /* ì œëª© ìƒ‰ìƒ (OP.GG ë¸Œëœë“œ ë¸”ë£¨ í¬ì¸íŠ¸) */
        h1 {
            color: #5383e8 !important;
            font-weight: 700;
        }
        h2, h3 {
            color: #23292f !important;
        }

        /* ì±„íŒ… ì…ë ¥ì°½ ìŠ¤íƒ€ì¼ (í™”ì´íŠ¸ ë°•ìŠ¤) */
        div[data-testid="stChatInput"] > div {
            background-color: #ffffff !important;
            border: 1px solid #dce2f0 !important;
            border-radius: 4px; /* ì‚´ì§ ëœ ë‘¥ê¸€ê²Œ */
            box-shadow: 0 2px 4px rgba(0,0,0,0.05);
        }

        /* ì…ë ¥ì°½ í…ìŠ¤íŠ¸ ì˜ì—­ */
        div[data-testid="stChatInput"] textarea {
            background-color: transparent !important;
            color: #23292f !important; /* ì–´ë‘ìš´ ê¸€ì”¨ */
        }
        
        /* í”Œë ˆì´ìŠ¤í™€ë” í…ìŠ¤íŠ¸ */
        div[data-testid="stChatInput"] textarea::placeholder {
            color: #9aa4af !important;
        }

        /* í¬ì»¤ìŠ¤ íš¨ê³¼ (ë¸Œëœë“œ ë¸”ë£¨) */
        div[data-testid="stChatInput"] > div:focus-within {
            border-color: #5383e8 !important;
            box-shadow: 0 0 0 1px #5383e8 !important;
        }

        /* ë²„íŠ¼ ìŠ¤íƒ€ì¼ (ë¸Œëœë“œ ë¸”ë£¨) */
        .stButton button {
            background-color: #5383e8;
            color: white;
            border: none;
            border-radius: 4px;
            font-weight: bold;
        }
        .stButton button:hover {
            background-color: #426cb7;
            color: white;
        }

        /* ë©”ì‹œì§€ ë°•ìŠ¤ ìŠ¤íƒ€ì¼ (ì±„íŒ… í’ì„  ëŠë‚Œ) */
        .stChatMessage {
            background-color: transparent;
        }
        
        /* ì‚¬ìš©ì/AI ë©”ì‹œì§€ êµ¬ë¶„ê° (ì„ íƒ ì‚¬í•­) */
        [data-testid="chatAvatarIcon-user"] {
            background-color: #5383e8;
        }
        [data-testid="chatAvatarIcon-assistant"] {
            background-color: #ffb900; /* AIëŠ” ë…¸ë€ìƒ‰ í¬ì¸íŠ¸ */
        }
    </style>
    """,
    unsafe_allow_html=True
)

# ì‚¬ì´ë“œë°” ë„¤ë¹„ê²Œì´ì…˜
with st.sidebar:
    st.title("ë©”ë‰´")
    selection = st.radio("ì´ë™í•  í˜ì´ì§€ë¥¼ ì„ íƒí•˜ì„¸ìš”:", ["ğŸ¤– ì±—ë´‡", "ğŸ“„ Macro Takling Point", "ğŸ“ˆ ì „ëµ ì‹¤í—˜ì‹¤ (Beta)", "ğŸ¤– AI ëª¨ë¸ í…ŒìŠ¤íŒ…", "âš–ï¸ í¬íŠ¸í´ë¦¬ì˜¤ ìµœì í™”", "ğŸ” ê¸°ìˆ ì  íŒ¨í„´ ìŠ¤ìºë„ˆ", "ğŸ” ETF êµ¬ì„± ì¢…ëª© ê²€ìƒ‰"], label_visibility="collapsed")

import requests

# -----------------------------------------------------------------------------
# Helper Functions for Ticker Fetching
# -----------------------------------------------------------------------------
@st.cache_data
def get_sp500_tickers():
    """Wikipediaì—ì„œ S&P 500 ì¢…ëª© ë¦¬ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    try:
        url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}
        response = requests.get(url, headers=headers)
        tables = pd.read_html(response.text)
        df = tables[0]
        tickers = df['Symbol'].tolist()
        return [t.replace('.', '-') for t in tickers] # BRK.B -> BRK-B ë³€í™˜
    except Exception as e:
        st.error(f"S&P 500 ë¦¬ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜: {e}")
        return []

@st.cache_data
def get_nasdaq100_tickers():
    """Wikipediaì—ì„œ NASDAQ 100 ì¢…ëª© ë¦¬ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    try:
        url = 'https://en.wikipedia.org/wiki/Nasdaq-100'
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}
        response = requests.get(url, headers=headers)
        tables = pd.read_html(response.text)
        # í…Œì´ë¸” ì¸ë±ìŠ¤ê°€ ë°”ë€” ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì—´ ì´ë¦„ìœ¼ë¡œ í™•ì¸
        for table in tables:
            if 'Ticker' in table.columns:
                return [t.replace('.', '-') for t in table['Ticker'].tolist()]
            elif 'Symbol' in table.columns:
                return [t.replace('.', '-') for t in table['Symbol'].tolist()]
        return []
    except Exception as e:
        st.error(f"NASDAQ 100 ë¦¬ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜: {e}")
        return []


if selection == "ğŸ¤– ì±—ë´‡":
    st.title("ğŸ¤– ë¡œë³´ì–´ë“œë°”ì´ì € ìƒë‹´")
    st.caption("FAQ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ AIê°€ ë‹µë³€í•´ ë“œë¦½ë‹ˆë‹¤.")

    if "messages" not in st.session_state:
        st.session_state.messages = []

    # ê¸°ì¡´ ëŒ€í™” ê¸°ë¡ í‘œì‹œ
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # ì¶”ì²œ ì§ˆë¬¸ (FAQ) ì˜ì—­ - ëŒ€í™” ê¸°ë¡ ì•„ë˜ì— ë°°ì¹˜
    # ëª…í™•í•œ í‚¤ì›Œë“œë¡œ ì§ì ‘ ì •ì˜
    faq_keywords = [
        "ì„œë¹„ìŠ¤ ê°€ì…/ì„¤ê³„",
        "í¬íŠ¸í´ë¦¬ì˜¤ ë¹„ì¤‘ ìˆ˜ì •",
        "í‡´ì§ì—°ê¸ˆ ê°€ì…ì œí•œ",
        "ê°œì¸ì—°ê¸ˆ ê°€ì…ì œí•œ",
        "ë§¤ë§¤/ë¦¬ë°¸ëŸ°ì‹± ê·œì¹™",
        "ìˆ˜ìµë¥  ë¯¸ë…¸ì¶œ ì‚¬ìœ ",
        "ì£¼ìš” ì—ëŸ¬ ì‚¬ë¡€"
    ]

    with st.expander("ğŸ’¡ ìì£¼ ë¬»ëŠ” ì§ˆë¬¸ (ì¶”ì²œ í‚¤ì›Œë“œ)"):
        st.caption("ê¶ê¸ˆí•œ ë‚´ìš©ì„ í´ë¦­í•´ë³´ì„¸ìš”.")
        cols = st.columns(4) # 4ì—´ë¡œ ë°°ì¹˜
        for i, keyword in enumerate(faq_keywords):
            if cols[i % 4].button(keyword, key=f"faq_{i}"):
                st.session_state.messages.append({"role": "user", "content": f"{keyword}ì— ëŒ€í•´ ì•Œë ¤ì¤˜"})
                st.rerun()
            
    # ê°€ì¥ ìµœê·¼ ë©”ì‹œì§€ê°€ userì´ê³  assistantì˜ ë‹µë³€ì´ ì—†ì„ ë•Œ (ë²„íŠ¼ í´ë¦­ ì§í›„) ë‹µë³€ ìƒì„± íŠ¸ë¦¬ê±°
    if st.session_state.messages and st.session_state.messages[-1]["role"] == "user":
        # ì´ë¯¸ ë‹µë³€ì´ ë‹¬ë¦° ì ì´ ìˆëŠ”ì§€ í™•ì¸ (ë§ˆì§€ë§‰ì´ userë©´ ë‹µë³€í•´ì•¼ í•¨)
        # í•˜ì§€ë§Œ Streamlit êµ¬ì¡°ìƒ chat_input ë£¨í”„ ë°–ì—ì„œ ì²˜ë¦¬í•´ì•¼ ìì—°ìŠ¤ëŸ¬ì›€.
        # ì—¬ê¸°ì„œëŠ” chat_inputì´ ì•„ë˜ì— ìˆì–´ì„œ, ë²„íŠ¼ í´ë¦­ -> rerun -> ì—¬ê¸°ê¹Œì§€ ì˜´ -> 
        # í™”ë©´ì— user msg í‘œì‹œë¨ -> ì´ì œ assistant msg í‘œì‹œí•  ì°¨ë¡€.
        
        # ë§ˆì§€ë§‰ ë©”ì‹œì§€ê°€ assistantê°€ ì•„ë‹ ê²½ìš°ì—ë§Œ ë‹µë³€ ìƒì„± ì‹œë„
        # (ì£¼ì˜: chat_inputì„ í†µí•œ ì…ë ¥ì€ ì•„ë˜ ë¸”ë¡ì—ì„œ ì²˜ë¦¬ë˜ë¯€ë¡œ, ì—¬ê¸°ì„œëŠ” ë²„íŠ¼ í´ë¦­ìœ¼ë¡œ ì¸í•œ ê²½ìš°ë§Œ ì²˜ë¦¬í•˜ë©´ ì¢‹ìŒ.
        #  ê·¸ëŸ¬ë‚˜ ê°„ë‹¨í•˜ê²Œì§ì „ ë©”ì‹œì§€ê°€ userë©´ ë¬´ì¡°ê±´ ë‹µë³€í•˜ê²Œ ë¡œì§ì„ í†µí•©í•˜ëŠ”ê²Œ ê¹”ë”í•¨.
        #  ë‹¤ë§Œ ì•„ë˜ chat_input ë¡œì§ê³¼ ì¤‘ë³µë˜ì§€ ì•Šê²Œ í•´ì•¼ í•¨.)
        pass 

    # ì‚¬ìš©ì ì§ˆë¬¸ ì…ë ¥
    if prompt := st.chat_input("ê¶ê¸ˆí•œ ì ì„ ì…ë ¥í•˜ì„¸ìš”"):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

    # ë‹µë³€ ìƒì„± ë¡œì§ (ë²„íŠ¼ í´ë¦­ or ì…ë ¥ì°½ ì…ë ¥ ê³µí†µ ì²˜ë¦¬)
    if st.session_state.messages and st.session_state.messages[-1]["role"] == "user":
        with st.chat_message("assistant"):
            try:
                # ë§ˆì§€ë§‰ ì‚¬ìš©ì ë©”ì‹œì§€ ê°€ì ¸ì˜¤ê¸°
                last_user_msg = st.session_state.messages[-1]["content"]
                # API Key Rotation ì ìš©
                full_prompt = f"ì§ˆë¬¸: {last_user_msg}\n\në‹µë³€ (í•œêµ­ì–´ë¡œ, ê¸ˆìœµ ì „ë¬¸ê°€ì²˜ëŸ¼):"
                response_text = generate_content_with_rotation(full_prompt)
                
                st.markdown(response_text)
                st.session_state.messages.append({"role": "assistant", "content": response_text})
                
            except Exception as e:
                st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

if selection == "ğŸ“„ Macro Takling Point":
    st.title("ğŸ“„ Macro Talking Point")
    st.caption("ê° ì§€ìˆ˜ì™€ ë‚ ì§œë³„ ë¦¬í¬íŠ¸ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    
    # ë¹„ë°€ë²ˆí˜¸ ë³´í˜¸ ê¸°ëŠ¥ ì¶”ê°€
    input_password = st.text_input("ì ‘ê·¼ ì•”í˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”", type="password")
    
    # Secretsì—ì„œ ì„¤ì •í•œ ë¹„ë°€ë²ˆí˜¸ì™€ ë¹„êµ
    correct_password = st.secrets["MACRO_PAGE_PASSWORD"]
    
    if input_password != correct_password:
        st.warning("ğŸ”’ ì˜¬ë°”ë¥¸ ì•”í˜¸ë¥¼ ì…ë ¥í•´ì•¼ ë‚´ìš©ì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        st.stop()
        
    st.success("ğŸ”“ ì¸ì¦ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    # -----------------------------------------------------------------------------
    # HTML ë¦¬í¬íŠ¸ ë·°ì–´ (Iframe ë°©ì‹)
    # -----------------------------------------------------------------------------
    # ì§€ì •ëœ ë””ë ‰í† ë¦¬ ë‚´ì˜ ëª¨ë“  HTML íŒŒì¼ì„ ì°¾ì•„ì„œ ëª©ë¡ìœ¼ë¡œ ë³´ì—¬ì¤ë‹ˆë‹¤.
    # NOTE: The original code used glob.glob and a specific naming convention.
    # The provided snippet suggests a different directory and naming convention.
    # For this edit, I will assume the user wants to keep the original report loading
    # mechanism but add the password protection.
    # If the user intended to replace the report loading logic, a separate instruction
    # would be needed.
    
    # ë¦¬í¬íŠ¸ íŒŒì¼ ìŠ¤ìº” í•¨ìˆ˜
    def get_reports():
        # í˜„ì¬ ë””ë ‰í† ë¦¬ì˜ html íŒŒì¼ ê²€ìƒ‰
        files = glob.glob("Macro Talking Point_ *.html")
        reports = []
        for f in files:
            # íŒŒì¼ëª… íŒŒì‹±: "Macro Talking Point_ {Index}_{Date}.html"
            # ì˜ˆ: "Macro Talking Point_ CPI_20251216.html"
            match = re.search(r"Macro Talking Point_ (.+?)_(\d+)\.html", f)
            if match:
                index_name = match.group(1)
                date_str = match.group(2)
                reports.append({
                    "filename": f,
                    "index": index_name,
                    "date": date_str,
                    "display": f"[{date_str}] {index_name}"
                })
        
        # ë‚ ì§œ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
        reports.sort(key=lambda x: x["date"], reverse=True)
        return reports


    reports = get_reports()

    if not reports:
        st.warning("í‘œì‹œí•  ë¦¬í¬íŠ¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        # ë„¤ë¹„ê²Œì´ì…˜(ë¦¬í¬íŠ¸ ëª©ë¡)ì„ ì‚¬ì´ë“œë°”ì— ë°°ì¹˜í•˜ì—¬ ìŠ¤í¬ë¡¤ ì‹œì—ë„ ê³ ì •ë˜ë„ë¡ ë³€ê²½
        with st.sidebar:
            st.divider() # ë©”ë‰´ì™€ êµ¬ë¶„ì„ 
            st.markdown("### ğŸ“‘ ë¦¬í¬íŠ¸ ëª©ë¡")
            
            # 1. ì¹´í…Œê³ ë¦¬ í•„í„°ë§
            categories = sorted(list(set([r["index"] for r in reports])))
            categories.insert(0, "All")
            
            selected_category = st.selectbox("ì¹´í…Œê³ ë¦¬ ì„ íƒ:", categories)
            
            # ì„ íƒëœ ì¹´í…Œê³ ë¦¬ì— ë”°ë¼ ë¦¬í¬íŠ¸ í•„í„°ë§
            if selected_category == "All":
                filtered_reports = reports
            else:
                filtered_reports = [r for r in reports if r["index"] == selected_category]
            
            # 2. ë¦¬í¬íŠ¸ ì„ íƒ
            if not filtered_reports:
                st.info("í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì— ë¦¬í¬íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
                selected_report = None
            else:
                report_options = [r["display"] for r in filtered_reports]
                selected_option = st.radio("ë³´ê³  ì‹¶ì€ ë¦¬í¬íŠ¸ë¥¼ ì„ íƒí•˜ì„¸ìš”:", report_options)
                
                # ì„ íƒëœ ë¦¬í¬íŠ¸ ì •ë³´ ì°¾ê¸°
                selected_report = next((r for r in reports if r["display"] == selected_option), None)

        if selected_report:
            # 1. ìŠ¤í¬ë¡¤ ì•µì»¤ ì‚½ì… (ì´ ìœ„ì¹˜ë¡œ ìŠ¤í¬ë¡¤ì„ ë•¡ê²¨ì˜¬ ì˜ˆì •)
            st.markdown('<div id="scroll-to-top-anchor"></div>', unsafe_allow_html=True)
            
            # ë¦¬í¬íŠ¸ ë³€ê²½ ì‹œ ìŠ¤í¬ë¡¤ì„ ë§¨ ìœ„ë¡œ ì´ˆê¸°í™” (JS Injection)
            current_report_key = selected_report["filename"]
            if "last_viewed_report" not in st.session_state:
                st.session_state["last_viewed_report"] = None

            if st.session_state["last_viewed_report"] != current_report_key:
                st.session_state["last_viewed_report"] = current_report_key
                components.html(
                    f"""
                    <script>
                        // ë¦¬í¬íŠ¸ í‚¤ê°€ ë°”ë€” ë•Œë§ˆë‹¤ ì‹¤í–‰: {current_report_key}
                        // ì•µì»¤(scroll-to-top-anchor)ë¥¼ ì°¾ì•„ì„œ scrollIntoView() í˜¸ì¶œ
                        // ë Œë”ë§ íƒ€ì´ë° ë¬¸ì œë¥¼ í”¼í•˜ê¸° ìœ„í•´ ë‹¤ì¤‘ ì‹œë„ (Burst)
                        function forceScroll() {{
                            try {{
                                var anchor = window.parent.document.getElementById("scroll-to-top-anchor");
                                if (anchor) {{
                                    anchor.scrollIntoView({{behavior: 'auto', block: 'start'}});
                                }}
                            }} catch(e) {{}}
                        }}
                        
                        // ì‹œë„ 1: ì¦‰ì‹œ
                        forceScroll(); 
                        // ì‹œë„ 2: 0.3ì´ˆ í›„ (DOM ë Œë”ë§ ì™„ë£Œ ì˜ˆìƒ)
                        setTimeout(forceScroll, 300);
                        // ì‹œë„ 3: 0.8ì´ˆ í›„ (í˜¹ì‹œ ëŠ¦ê²Œ ë¡œë”©ë  ê²½ìš°)
                        setTimeout(forceScroll, 800);
                    </script>
                    """,
                    height=0,
                    width=0
                )

            st.markdown(f"### ğŸ“‘ {selected_report['index']} ({selected_report['date']})")
            
            try:
                with open(selected_report["filename"], "r", encoding="utf-8") as f:
                    html_content = f.read()
                
                # ë†’ì´ ê³„ì‚° ë¡œì§ ê°œì„  (ë„ˆë¬´ ê¸¸ì§€ ì•Šê²Œ íŠœë‹)
                # HTML íƒœê·¸ë“¤ì´ ë§ìœ¼ë¯€ë¡œ ë¼ì¸ ìˆ˜ * 15px ì •ë„ë¡œ ì¶•ì†Œ ê³„ì‚° (ê¸°ì¡´ 25px -> 15px)
                line_count = len(html_content.splitlines())
                
                # ë¼ì¸ ìˆ˜ê°€ ë„ˆë¬´ ì ìœ¼ë©´(minified) ê¸°ë³¸ ë†’ì´ ë¶€ì—¬, ì•„ë‹ˆë©´ ë¼ì¸ ìˆ˜ ë¹„ë¡€
                if line_count < 50:
                    estimated_height = 1200
                else:
                    estimated_height = max(800, line_count * 15 + 50)

                components.html(html_content, height=estimated_height, scrolling=True)
                
            except Exception as e:
                st.error(f"íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

if selection == "ğŸ“ˆ ì „ëµ ì‹¤í—˜ì‹¤ (Beta)":
    st.title("ğŸ“ˆ ë‚˜ë§Œì˜ ì£¼ì‹ ì „ëµ ì‹¤í—˜ì‹¤ (Beta)")
    st.caption("ëŒ€í‘œì ì¸ íˆ¬ì ì „ëµë“¤ì„ ë‚´ ì…ë§›ëŒ€ë¡œ ì„¤ì •í•´ì„œ ê²€ì¦í•´ë³´ì„¸ìš”.")

    # 1. ì„¤ì • ì…ë ¥
    with st.expander("âš™ï¸ ë°±í…ŒìŠ¤íŒ… ì„¤ì •", expanded=True):
        col1, col2, col3 = st.columns(3)
        with col1:
            ticker_input = st.text_input("ì¢…ëª© ì½”ë“œ (ì—¬ëŸ¬ ê°œëŠ” ì‰¼í‘œë¡œ êµ¬ë¶„)", value="SPY, QQQ, AAPL")
        with col2:
            start_date = st.date_input("ì‹œì‘ì¼", value=pd.to_datetime("2023-01-01"))
        with col3:
            end_date = st.date_input("ì¢…ë£Œì¼", value=pd.to_datetime("today"))

    st.divider()

    # 2. ì „ëµ ì„ íƒ ë° íŒŒë¼ë¯¸í„° ì„¤ì •
    st.subheader("ğŸ› ï¸ ì „ëµ êµ¬ì„±í•˜ê¸°")
    
    strategy_type = st.selectbox(
        "ì‚¬ìš©í•  ì „ëµì„ ì„ íƒí•˜ì„¸ìš”.",
        ["ì´ë™í‰ê· ì„  í¬ë¡œìŠ¤ (MA Crossover)", "RSI (ìƒëŒ€ê°•ë„ì§€ìˆ˜)", "ë³¼ë¦°ì € ë°´ë“œ (Bollinger Bands)"]
    )

    # ì „ëµë³„ íŒŒë¼ë¯¸í„° UI (ë™ì  ë³€ê²½)
    params = {}
    if strategy_type == "ì´ë™í‰ê· ì„  í¬ë¡œìŠ¤ (MA Crossover)":
        st.info("ğŸ’¡ **ê³¨ë“ í¬ë¡œìŠ¤ ì „ëµ**: ë‹¨ê¸° ì´í‰ì„ ì´ ì¥ê¸° ì´í‰ì„ ì„ ëŒíŒŒí•˜ë©´ ë§¤ìˆ˜, ê¹¨ì§€ë©´ ë§¤ë„í•©ë‹ˆë‹¤.")
        col_p1, col_p2 = st.columns(2)
        with col_p1:
            params['short_window'] = st.number_input("ë‹¨ê¸° ì´ë™í‰ê·  (ì¼)", value=20, min_value=1)
        with col_p2:
            params['long_window'] = st.number_input("ì¥ê¸° ì´ë™í‰ê·  (ì¼)", value=60, min_value=1)

    elif strategy_type == "RSI (ìƒëŒ€ê°•ë„ì§€ìˆ˜)":
        st.info("ğŸ’¡ **RSI ì—­ì¶”ì„¸ ì „ëµ**: ê³¼ë§¤ë„ êµ¬ê°„(ë§¤ìˆ˜ ê¸°ì¤€ ë¯¸ë§Œ)ì—ì„œ ë§¤ìˆ˜í•˜ê³ , ê³¼ë§¤ìˆ˜ êµ¬ê°„(ë§¤ë„ ê¸°ì¤€ ì´ˆê³¼)ì—ì„œ ë§¤ë„í•©ë‹ˆë‹¤.")
        col_p1, col_p2, col_p3 = st.columns(3)
        with col_p1:
            params['window'] = st.number_input("RSI ê¸°ê°„", value=14, min_value=1)
        with col_p2:
            params['buy_threshold'] = st.number_input("ë§¤ìˆ˜ ê¸°ì¤€ (ê³¼ë§¤ë„)", value=30, min_value=0, max_value=100)
        with col_p3:
            params['sell_threshold'] = st.number_input("ë§¤ë„ ê¸°ì¤€ (ê³¼ë§¤ìˆ˜)", value=70, min_value=0, max_value=100)

    elif strategy_type == "ë³¼ë¦°ì € ë°´ë“œ (Bollinger Bands)":
        st.info("ğŸ’¡ **ë³¼ë¦°ì € ë°´ë“œ ì „ëµ**: ì£¼ê°€ê°€ í•˜ë‹¨ ë°´ë“œë¥¼ í„°ì¹˜í•˜ë©´ ë§¤ìˆ˜, ìƒë‹¨ ë°´ë“œë¥¼ í„°ì¹˜í•˜ë©´ ë§¤ë„í•©ë‹ˆë‹¤ (í‰ê·  íšŒê·€).")
        col_p1, col_p2 = st.columns(2)
        with col_p1:
            params['window'] = st.number_input("ì´ë™í‰ê·  ê¸°ê°„", value=20, min_value=1)
        with col_p2:
            params['std_dev'] = st.number_input("í‘œì¤€í¸ì°¨ ìŠ¹ìˆ˜ (Standard Deviation multiplier)", value=2.0, step=0.1)

    # 3. ì „ëµ ì‹¤í–‰ ë¡œì§
    if st.button("ğŸš€ ì „ëµ ë¶„ì„ ì‹¤í–‰"):
        with st.spinner("ë°ì´í„° ë¶„ì„ ë° ì „ëµ ì‹œë®¬ë ˆì´ì…˜ ì¤‘..."):
            # ì…ë ¥ëœ í‹°ì»¤ íŒŒì‹± (ì‰¼í‘œ êµ¬ë¶„)
            tickers = [t.strip().upper() for t in ticker_input.split(',') if t.strip()]
            
            if not tickers:
                st.warning("ì¢…ëª© ì½”ë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                st.stop()
            
            results_list = []
            equity_curves = pd.DataFrame()
            
            # ì§„í–‰ìƒí™©ë°”
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            # SPY ë²¤ì¹˜ë§ˆí¬ ë°ì´í„° ë‹¤ìš´ë¡œë“œ (ì‹œì¥ ìˆ˜ìµë¥  ë¹„êµìš©)
            spy_total_return = 0.0
            try:
                spy_df = yf.download("SPY", start=start_date, end=end_date, progress=False)
                if not spy_df.empty:
                    if isinstance(spy_df.columns, pd.MultiIndex):
                        spy_df.columns = spy_df.columns.get_level_values(0)
                    
                    if 'Adj Close' not in spy_df.columns:
                         if 'Close' in spy_df.columns:
                            spy_df['Adj Close'] = spy_df['Close']
                    
                    if 'Adj Close' in spy_df.columns:
                        spy_return_series = spy_df['Adj Close'].pct_change()
                        spy_cum_return = (1 + spy_return_series).cumprod()
                        spy_total_return = spy_cum_return.iloc[-1] - 1
            except Exception as e:
                st.warning(f"SPY ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")

            for i, ticker in enumerate(tickers):
                status_text.text(f"ë¶„ì„ ì¤‘: {ticker} ({i+1}/{len(tickers)})")
                try:
                    # A. ë°ì´í„° ë‹¤ìš´ë¡œë“œ
                    df = yf.download(ticker, start=start_date, end=end_date, progress=False)
                    
                    if df.empty:
                        st.warning(f"'{ticker}': ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
                        continue
                    
                    # yfinance ìµœì‹  ë²„ì „ í˜¸í™˜ì„±
                    if isinstance(df.columns, pd.MultiIndex):
                        try:
                            df.columns = df.columns.get_level_values(0)
                        except:
                            pass

                    # ì»¬ëŸ¼ ì´ë¦„ ì •ë¦¬
                    if 'Adj Close' not in df.columns:
                        if 'Close' in df.columns:
                            df['Adj Close'] = df['Close']
                        else:
                            st.warning(f"'{ticker}': ê°€ê²© ë°ì´í„° ë¶€ì¡±. ê±´ë„ˆëœë‹ˆë‹¤.")
                            continue
                    
                    # ìˆ˜ìµë¥  ê³„ì‚°
                    df = df.copy() # ê²½ê³  ë°©ì§€
                    df['Return'] = df['Adj Close'].pct_change()
                    df.dropna(inplace=True)
                    
                    # B. ì „ëµ ë¡œì§ ê³„ì‚°
                    df['Signal'] = 0 

                    # ---------------- [ì „ëµ í•¨ìˆ˜ ì ìš©] ----------------
                    if strategy_type == "ì´ë™í‰ê· ì„  í¬ë¡œìŠ¤ (MA Crossover)":
                        df['MA_Short'] = df['Adj Close'].rolling(window=params['short_window']).mean()
                        df['MA_Long'] = df['Adj Close'].rolling(window=params['long_window']).mean()
                        df.loc[df['MA_Short'] > df['MA_Long'], 'Signal'] = 1
                    
                    elif strategy_type == "RSI (ìƒëŒ€ê°•ë„ì§€ìˆ˜)":
                        delta = df['Adj Close'].diff()
                        gain = (delta.where(delta > 0, 0)).rolling(window=params['window']).mean()
                        loss = (-delta.where(delta < 0, 0)).rolling(window=params['window']).mean()
                        rs = gain / loss
                        df['RSI'] = 100 - (100 / (1 + rs))
                        
                        import numpy as np
                        df['Signal'] = np.nan
                        df.loc[df['RSI'] < params['buy_threshold'], 'Signal'] = 1
                        df.loc[df['RSI'] > params['sell_threshold'], 'Signal'] = 0
                        df['Signal'] = df['Signal'].ffill().fillna(0)

                    elif strategy_type == "ë³¼ë¦°ì € ë°´ë“œ (Bollinger Bands)":
                        df['MA'] = df['Adj Close'].rolling(window=params['window']).mean()
                        df['Std'] = df['Adj Close'].rolling(window=params['window']).std()
                        df['Upper'] = df['MA'] + (df['Std'] * params['std_dev'])
                        df['Lower'] = df['MA'] - (df['Std'] * params['std_dev'])
                        
                        import numpy as np
                        df['Signal'] = np.nan
                        df.loc[df['Adj Close'] < df['Lower'], 'Signal'] = 1
                        df.loc[df['Adj Close'] > df['Upper'], 'Signal'] = 0
                        df['Signal'] = df['Signal'].ffill().fillna(0)
                    # ------------------------------------------------

                    # C. ì„±ê³¼ ê³„ì‚°
                    df['Strategy_Return'] = df['Signal'].shift(1) * df['Return']
                    df['Cumulative_Strategy'] = (1 + df['Strategy_Return'].fillna(0)).cumprod()
                    df['Cumulative_Market'] = (1 + df['Return']).cumprod()
                    
                    # MDD
                    drawdown = df['Cumulative_Strategy'] / df['Cumulative_Strategy'].cummax() - 1
                    mdd = drawdown.min()
                    
                    # ìµœì¢… ìˆ˜ìµë¥ 
                    total_return = df['Cumulative_Strategy'].iloc[-1] - 1
                    market_return = df['Cumulative_Market'].iloc[-1] - 1 # Buy & Hold return
                    
                    # Alpha vs SPY
                    alpha_spy = total_return - spy_total_return

                    # ê²°ê³¼ ì €ì¥
                    results_list.append({
                        "ì¢…ëª©": ticker,
                        "ì „ëµ ìˆ˜ìµë¥ ": f"{total_return:.2%}",
                        "ìì²´ B&H": f"{market_return:.2%}", # Buy and Hold
                        "SPY ìˆ˜ìµë¥ ": f"{spy_total_return:.2%}",
                        "Alpha(vs SPY)": f"{alpha_spy:.2%}",
                        "MDD": f"{mdd:.2%}",
                        "Raw_Return": total_return # ì •ë ¬ìš©
                    })
                    
                    # ì°¨íŠ¸ìš© ë°ì´í„° (ì¸ë±ìŠ¤ í†µì¼)
                    equity_curves[ticker] = df['Cumulative_Strategy']
                
                except Exception as e:
                    st.warning(f"'{ticker}' ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
                
                # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
                progress_bar.progress((i + 1) / len(tickers))
            
            status_text.empty()
            progress_bar.empty()

            if results_list:
                st.success(f"ì´ {len(results_list)}ê°œ ì¢…ëª© ë¶„ì„ ì™„ë£Œ!")
                
                # 1. ìš”ì•½ í…Œì´ë¸” (ìˆ˜ìµë¥  ìˆœ ì •ë ¬)
                results_df = pd.DataFrame(results_list)
                results_df = results_df.sort_values(by="Raw_Return", ascending=False).drop(columns=["Raw_Return"])
                
                st.subheader("ğŸ“Š ì¢…ëª©ë³„ ì„±ê³¼ (ìˆ˜ìµë¥  ìˆœ)")
                st.caption(f"SPY(S&P 500) ìˆ˜ìµë¥  ({start_date} ~ {end_date}): **{spy_total_return:.2%}**")
                st.dataframe(results_df, use_container_width=True)
                
                # 2. ë¹„êµ ì°¨íŠ¸
                st.subheader("ğŸ“ˆ ìˆ˜ìµë¥  ë¹„êµ ì°¨íŠ¸")
                if not equity_curves.empty:
                    # ì¸ë±ìŠ¤(ë‚ ì§œ)ê°€ ì„œë¡œ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ fillna
                    equity_curves = equity_curves.fillna(method='ffill').fillna(1.0)
                    fig = px.line(equity_curves, title=f"ì „ëµ ëˆ„ì  ìˆ˜ìµë¥  ë¹„êµ ({strategy_type})")
                    st.plotly_chart(fig, use_container_width=True)
            else:
                st.error("ë¶„ì„ëœ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. í‹°ì»¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")

elif selection == "ğŸ¤– AI ëª¨ë¸ í…ŒìŠ¤íŒ…":
    st.title("ğŸ¤– AI íŠ¸ë ˆì´ë”© ëª¨ë¸ ì—°êµ¬ì†Œ")
    st.caption("ê³¼ê±° ë°ì´í„°ë¡œ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì„ í•™ìŠµì‹œì¼œ ë¯¸ë˜ ìˆ˜ìµë¥ ì„ ì˜ˆì¸¡í•˜ê³  ê²€ì¦í•©ë‹ˆë‹¤.")

    # Session State ì´ˆê¸°í™”
    if 'trained_models' not in st.session_state:
        st.session_state.trained_models = {}
    if 'gemini_insights' not in st.session_state:
        st.session_state.gemini_insights = {}

    # 1. ì„¤ì •
    with st.expander("âš™ï¸ ëª¨ë¸ë§ ì„¤ì •", expanded=True):
        col1, col2 = st.columns(2)
        with col1:
            universe_preset = st.selectbox(
                "ë¶„ì„ ëŒ€ìƒ ìœ ë‹ˆë²„ìŠ¤", 
                ["ì§ì ‘ ì…ë ¥", "NASDAQ Top 10 (Demo)", "Tech Giants (M7)", "NASDAQ Top 30 (Big Tech)", "S&P 500 Top 50 (Sector Leaders)"]
            )
            
            if universe_preset == "ì§ì ‘ ì…ë ¥":
                tickers_input = st.text_input("ì¢…ëª© ì½”ë“œ ì…ë ¥ (ì‰¼í‘œ êµ¬ë¶„)", "AAPL, MSFT, GOOGL, AMZN, NVDA")
                tickers = [t.strip().upper() for t in tickers_input.split(",") if t.strip()]
            
            elif universe_preset == "Tech Giants (M7)":
                tickers = ["AAPL", "MSFT", "GOOGL", "AMZN", "NVDA", "META", "TSLA"]
            
            elif universe_preset == "NASDAQ Top 10 (Demo)":
                tickers = ["AAPL", "MSFT", "NVDA", "GOOGL", "AMZN", "META", "TSLA", "AVGO", "COST", "PEP"]

            elif universe_preset == "NASDAQ Top 30 (Big Tech)":
                # ì‹œê°€ì´ì•¡ ìƒìœ„ ë“± ì£¼ìš” 30ê°œ ì¢…ëª©
                tickers = [
                    "AAPL", "MSFT", "NVDA", "GOOGL", "AMZN", "META", "TSLA", "AVGO", "COST", "PEP",
                    "CSCO", "NFLX", "AMD", "ADBE", "TMUS", "INTC", "QCOM", "TXN", "AMGN", "HON",
                    "AMAT", "INTU", "SBUX", "ADP", "BKNG", "GILD", "ISRG", "MDLZ", "REGN", "VRTX"
                ]
            
            elif universe_preset == "S&P 500 Top 50 (Sector Leaders)":
                # S&P 500 ì£¼ìš” ì¢…ëª© 50ê°œ (ì˜ˆì‹œ)
                tickers = [
                    "AAPL", "MSFT", "NVDA", "GOOGL", "AMZN", "META", "TSLA", "BRK-B", "LLY", "V",
                    "TSM", "UNH", "XOM", "JPM", "JNJ", "WMT", "MA", "PG", "HD", "AVGO", 
                    "CVX", "MRK", "ABBV", "COST", "PEP", "KO", "ADBE", "BAC", "CSCO", "CRM",
                    "MCD", "TMO", "ACN", "NFLX", "AMD", "LIN", "ABT", "DHR", "DIS", "NKE",
                    "WFC", "TXN", "NEE", "PM", "VZ", "RTX", "INTC", "QCOM", "UPS", "HON"
                ]

            if universe_preset != "ì§ì ‘ ì…ë ¥":
                st.info(f"ì„ íƒëœ ìœ ë‹ˆë²„ìŠ¤: {len(tickers)}ê°œ ì¢…ëª©")

        with col2:
            model_type = st.selectbox("ì‚¬ìš©í•  AI ëª¨ë¸", ["Linear Regression (ì„ í˜•íšŒê·€)", "LightGBM (íŠ¸ë¦¬ ë¶€ìŠ¤íŒ…)", "SVM (Support Vector Machine)"])
            
            # Feature ë³µì¡ë„ ì„ íƒ
            feature_level = st.radio(
                "Feature ë³µì¡ë„ (AI ì§€ëŠ¥)", 
                ["Light (5ê°œ - ì†ë„ ì¤‘ì‹¬)", "Standard (22ê°œ - ê· í˜•)", "Rich (50+ê°œ - ì •ë°€ ë¶„ì„)"],
                index=1
            )
            
            # Top-K ì„ íƒ
            top_k_select = st.number_input("ì¼ì¼ ë§¤ìˆ˜ ì¢…ëª© ìˆ˜ (Top K)", min_value=1, max_value=10, value=3)
    
        col_d1, col_d2 = st.columns(2)
        with col_d1:
            train_start = st.date_input("í•™ìŠµ ì‹œì‘ì¼", pd.to_datetime("2020-01-01"))
        with col_d2:
            test_start = st.date_input("í…ŒìŠ¤íŠ¸ ì‹œì‘ì¼ (Backtest Start)", pd.to_datetime("2023-01-01"))

    # 2. ì‹¤í–‰ (í•™ìŠµ ë²„íŠ¼)
    if st.button("ğŸ§  AI ëª¨ë¸ í•™ìŠµ ì‹œì‘"):
        status_text = st.empty()
        progress_bar = st.progress(0)
        
        # A. ë°ì´í„° ìˆ˜ì§‘ ë° í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§
        status_text.text("ë°ì´í„° ë‹¤ìš´ë¡œë“œ ë° í”¼ì²˜ ìƒì„± ì¤‘...")
        
        full_data = {}
        valid_tickers = []
        
        # ì „ì²´ ê¸°ê°„ ì„¤ì •
        end_date = pd.to_datetime("today")
        
        for i, ticker in enumerate(tickers):
            try:
                # ë„‰ë„‰í•˜ê²Œ ë°›ì•„ì„œ ì´í‰ì„  ê³„ì‚° (Rich ëª¨ë“œì¼ ê²½ìš° ë” ë§ì´ í•„ìš”í•  ìˆ˜ ìˆìŒ)
                lookback_days = 200 if "Rich" in feature_level else 100
                df = yf.download(ticker, start=train_start - pd.Timedelta(days=lookback_days), end=end_date, progress=False)
                
                # MultiIndex ì²˜ë¦¬
                if isinstance(df.columns, pd.MultiIndex):
                    df.columns = df.columns.get_level_values(0)
                
                # ì»¬ëŸ¼ ë³´ì •
                if 'Adj Close' not in df.columns:
                    if 'Close' in df.columns:
                        df['Adj Close'] = df['Close']
                    else:
                        continue
                
                df = df[['Open', 'High', 'Low', 'Adj Close', 'Volume']].copy()
                df.columns = ['Open', 'High', 'Low', 'Close', 'Volume'] 
                
                # ---------------- [Feature Engineering] ----------------
                feature_cols = []
                
                # 1. Light (Basic 5)
                if "Light" in feature_level:
                    df['MA5'] = df['Close'].rolling(window=5).mean()
                    df['MA20'] = df['Close'].rolling(window=20).mean()
                    df['Disparity_5'] = df['Close'] / df['MA5']
                    df['Disparity_20'] = df['Close'] / df['MA20']
                    
                    # RSI
                    delta = df['Close'].diff()
                    gain = (delta.where(delta > 0, 0)).rolling(14).mean()
                    loss = (-delta.where(delta < 0, 0)).rolling(14).mean()
                    rs = gain / loss
                    df['RSI'] = 100 - (100 / (1 + rs))
                    
                    df['Volatility'] = df['Close'].pct_change().rolling(20).std()
                    df['Momentum_1M'] = df['Close'].pct_change(20)
                    
                    feature_cols = ['Disparity_5', 'Disparity_20', 'RSI', 'Volatility', 'Momentum_1M']

                else:
                    # Standard(22) or Rich(50+)
                    # ê³µí†µ: ì²´ê³„ì  Feature ìƒì„± (Windows Loop)
                    
                    # Windows ì„¤ì •
                    if "Rich" in feature_level:
                        windows = [3, 5, 10, 20, 40, 60, 120] # Rich: ì´ˆë‹¨ê¸°(3) ë° ì´ˆì¥ê¸°(120) ì¶”ê°€
                    else:
                        windows = [5, 10, 20, 60] # Standard

                    df['Ret_1d'] = df['Close'].pct_change()
                    
                    for w in windows:
                        col_roc = f'ROC_{w}'
                        df[col_roc] = df['Close'].pct_change(w)
                        feature_cols.append(col_roc)
                        
                        col_ma = f'MA_Dist_{w}'
                        ma = df['Close'].rolling(window=w).mean()
                        df[col_ma] = df['Close'] / ma
                        feature_cols.append(col_ma)
                        
                        col_vol = f'Vol_{w}'
                        df[col_vol] = df['Ret_1d'].rolling(window=w).std()
                        feature_cols.append(col_vol)
                        
                        col_vol_ratio = f'Vol_Ratio_{w}'
                        vol_ma = df['Volume'].rolling(window=w).mean()
                        df[col_vol_ratio] = df['Volume'] / vol_ma
                        feature_cols.append(col_vol_ratio)
                    
                    # RSI (Standard: 14, 60 / Rich: 9, 14, 28, 60)
                    rsi_windows = [9, 14, 28, 60] if "Rich" in feature_level else [14, 60]
                    for rsi_w in rsi_windows:
                        delta = df['Close'].diff()
                        gain = (delta.where(delta > 0, 0)).rolling(rsi_w).mean()
                        loss = (-delta.where(delta < 0, 0)).rolling(rsi_w).mean()
                        rs = gain / loss
                        col_rsi = f'RSI_{rsi_w}'
                        df[col_rsi] = 100 - (100 / (1 + rs))
                        feature_cols.append(col_rsi)

                    # [Rich Only Features] ì¶”ê°€
                    if "Rich" in feature_level:
                        # 1. Lagged Returns (ì‹œê³„ì—´ íŒ¨í„´)
                        for lag in [1, 2, 3, 5]:
                            col_lag = f'Ret_Lag_{lag}'
                            df[col_lag] = df['Ret_1d'].shift(lag)
                            feature_cols.append(col_lag)
                        
                        # 2. Candle Patterns
                        # Body Ratio (ëª¸í†µ ê¸¸ì´ / ì „ì²´ ê¸¸ì´)
                        df['Candle_Body'] = (df['Close'] - df['Open']).abs()
                        df['Candle_Len'] = (df['High'] - df['Low'])
                        df['Body_Ratio'] = df['Candle_Body'] / df['Candle_Len'].replace(0, 1) # Div by zero ë°©ì§€
                        feature_cols.append('Body_Ratio')
                        
                        # Shadow Upper/Lower
                        df['Shadow_Upper'] = (df['High'] - df[['Open', 'Close']].max(axis=1)) / df['Candle_Len'].replace(0, 1)
                        df['Shadow_Lower'] = (df[['Open', 'Close']].min(axis=1) - df['Low']) / df['Candle_Len'].replace(0, 1)
                        feature_cols.append('Shadow_Upper')
                        feature_cols.append('Shadow_Lower')
                        
                        # 3. Day of Week (ìš”ì¼ íš¨ê³¼)
                        # ì›í•« ì¸ì½”ë”© ëŒ€ì‹  ê°„ë‹¨íˆ ìˆ«ìë¡œ (íŠ¸ë¦¬ ëª¨ë¸ì€ ì´ê±°ë©´ ì¶©ë¶„)
                        df['DayOfWeek'] = df.index.dayofweek
                        feature_cols.append('DayOfWeek')

                # Label (Target): ë‹¤ìŒë‚  ìˆ˜ìµë¥ 
                df['Next_Return'] = df['Close'].pct_change().shift(-1)
                
                df.dropna(inplace=True)
                
                if not df.empty:
                    full_data[ticker] = df
                    valid_tickers.append(ticker)
                    
            except Exception as e:
                pass
            
            progress_bar.progress((i + 1) / len(tickers) * 0.3)

        if not valid_tickers:
            st.error("ìœ íš¨í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            st.stop()
            
        # B. ëª¨ë¸ í•™ìŠµ
        status_text.text(f"{model_type} ëª¨ë¸ í•™ìŠµ ì¤‘ (Features: {len(feature_cols)}ê°œ)...")
        
        # ì „ì²´ ë°ì´í„°ë¥¼ í•˜ë‚˜ì˜ í•™ìŠµì…‹ìœ¼ë¡œ ë³‘í•© (Global Model)
        X_train_all = []
        y_train_all = []
        
        # feature_colsëŠ” ìœ„ì—ì„œ ìë™ ìƒì„±ë¨
        
        test_datasets = {} 
        
        for ticker in valid_tickers:
            df = full_data[ticker]
            train_mask = df.index < pd.to_datetime(test_start)
            test_mask = df.index >= pd.to_datetime(test_start)
            
            train_df = df[train_mask]
            test_df = df[test_mask]
            
            if not train_df.empty:
                X_train_all.append(train_df[feature_cols].values)
                y_train_all.append(train_df['Next_Return'].values)
            
            if not test_df.empty:
                test_datasets[ticker] = test_df
        
        if not X_train_all:
            st.error("í•™ìŠµ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤ ê¸°ê°„ì„ ëŠ˜ë ¤ì£¼ì„¸ìš”.")
            st.stop()
            
        X_train = np.concatenate(X_train_all)
        y_train = np.concatenate(y_train_all)
        
        # Scaling
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        
        # Model Fitting
        if "Linear" in model_type:
            model = LinearRegression()
        elif "SVM" in model_type:
            if len(X_train) > 10000:
                st.warning("ë°ì´í„°ê°€ ë§ì•„ SVM í•™ìŠµ ì†ë„ê°€ ëŠë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            model = SVR(kernel='rbf', C=1.0, epsilon=0.1)
        elif "LightGBM" in model_type:
            model = lgb.LGBMRegressor(n_estimators=100, learning_rate=0.05, num_leaves=31, random_state=42, verbose=-1)
            
        model.fit(X_train_scaled, y_train)
        progress_bar.progress(0.7)
        
        # C. ì˜ˆì¸¡ ë° ë°±í…ŒìŠ¤íŒ… (Dynamic Top-K)
        status_text.text(f"ë°±í…ŒìŠ¤íŒ… ì‹œë®¬ë ˆì´ì…˜ ì¤‘ (Top {top_k_select})...")
        
        all_test_dates = sorted(list(set().union(*[d.index for d in test_datasets.values()])))
        
        strategy_capital = 1.0 
        benchmark_capital = 1.0
        portfolio_curve = []
        benchmark_curve = []
        dates = []
        
        current_capital = 1.0
        
        for date in all_test_dates:
            daily_scores = []
            daily_returns = [] 
            
            for ticker in valid_tickers:
                if ticker in test_datasets and date in test_datasets[ticker].index:
                    row = test_datasets[ticker].loc[date]
                    feats = row[feature_cols].values.reshape(1, -1)
                    feats_scaled = scaler.transform(feats)
                    score = model.predict(feats_scaled)[0]
                    daily_scores.append((ticker, score, row['Next_Return']))
                    daily_returns.append(row['Next_Return'])
            
            if not daily_scores:
                continue
                
            # Benchmark
            avg_daily_ret = np.mean(daily_returns)
            benchmark_capital *= (1 + avg_daily_ret)
            
            # Strategy: User Selected Top-K
            daily_scores.sort(key=lambda x: x[1], reverse=True) 
            
            # ì…ë ¥ëœ kë³´ë‹¤ ìœ íš¨ ì¢…ëª©ì´ ì ìœ¼ë©´ ê°€ëŠ¥í•œ ë§Œí¼ë§Œ ë§¤ìˆ˜
            actual_k = min(top_k_select, len(daily_scores))
            selected = daily_scores[:actual_k]
            
            if selected:
                strategy_daily_ret = np.mean([x[2] for x in selected])
            else:
                strategy_daily_ret = 0.0
                
            strategy_capital *= (1 + strategy_daily_ret)
            
            portfolio_curve.append(strategy_capital)
            benchmark_curve.append(benchmark_capital)
            dates.append(date)
            
        progress_bar.progress(1.0)
        status_text.empty()
        
        # D. ê²°ê³¼ ì €ì¥ (Session State)
        st.session_state.trained_models[model_type] = {
            "model": model,
            "scaler": scaler,
            "feature_cols": feature_cols,
            "full_data": full_data,
            "valid_tickers": valid_tickers,
            "top_k": top_k_select,   # ì €ì¥: í•™ìŠµí•  ë•Œ ì“´ Top-K
            "feature_level": feature_level # ì €ì¥: í•™ìŠµí•  ë•Œ ì“´ ë ˆë²¨
        }
        
        # E. ê²°ê³¼ ì‹œê°í™”
        results_df = pd.DataFrame({
            "Date": dates,
            "AI Model Portfolio": portfolio_curve,
            "Benchmark (Equal Weight)": benchmark_curve
        }).set_index("Date")
        
        st.success(f"í•™ìŠµ ì™„ë£Œ! ({model_type}) - Features: {len(feature_cols)}ê°œ, Top-{top_k_select}")
        
        total_ret = results_df['AI Model Portfolio'].iloc[-1] - 1
        bench_ret = results_df['Benchmark (Equal Weight)'].iloc[-1] - 1
        alpha = total_ret - bench_ret
        
        c1, c2, c3 = st.columns(3)
        c1.metric("AI í¬íŠ¸í´ë¦¬ì˜¤ ìˆ˜ìµë¥ ", f"{total_ret:.2%}", delta=f"{alpha:.2%}")
        c2.metric("ë²¤ì¹˜ë§ˆí¬ ìˆ˜ìµë¥ ", f"{bench_ret:.2%}")
        mdd_series = results_df['AI Model Portfolio'] / results_df['AI Model Portfolio'].cummax() - 1
        mdd = mdd_series.min()
        c3.metric("ìµœëŒ€ ë‚™í­ (MDD)", f"{mdd:.2%}")
        
        st.subheader(f"ğŸ“ˆ ë°±í…ŒìŠ¤íŒ… ê²°ê³¼: AI Top-{top_k_select} ì „ëµ vs ì‹œì¥")
        fig = px.line(results_df, title=f"{model_type} ê¸°ë°˜ Top-{top_k_select} ì „ëµ ì„±ê³¼")
        st.plotly_chart(fig, use_container_width=True)
        
        if "Linear" in model_type or "LightGBM" in model_type:
            st.subheader(f"ğŸ” ëª¨ë¸ ì¤‘ìš” Feature (Top 20 / {len(feature_cols)})")
            if "Linear" in model_type:
                importance = np.abs(model.coef_)
            else:
                importance = model.feature_importances_
            
            imp_df = pd.DataFrame({"Feature": feature_cols, "Importance": importance}).sort_values(by="Importance", ascending=False)
            st.bar_chart(imp_df.head(20).set_index("Feature"))

    # F. ì˜¤ëŠ˜ì˜ ì¶”ì²œ PICK (ë³„ë„ ì„¹ì…˜)
    st.divider()
    
    if not st.session_state.trained_models:
        st.subheader("ğŸ”® ì˜¤ëŠ˜ì˜ ì¶”ì²œ PICK")
        st.info("ğŸ‘† ìœ„ì—ì„œ ë¨¼ì € AI ëª¨ë¸ì„ í•™ìŠµì‹œì¼œì£¼ì„¸ìš”.")
    else:
        # í•™ìŠµëœ ëª¨ë¸ ì„ íƒ
        model_options = list(st.session_state.trained_models.keys())
        selected_model_name = st.selectbox("ì¶”ì²œì„ í™•ì¸í•  í•™ìŠµ ëª¨ë¸ ì„ íƒ", model_options)
        
        # ì €ì¥ëœ ëª¨ë¸ ì •ë³´ ë¡œë“œ
        saved_info = st.session_state.trained_models[selected_model_name]
        saved_top_k = saved_info.get("top_k", 3)
        
        st.subheader(f"ğŸ”® ì˜¤ëŠ˜ì˜ ì¶”ì²œ PICK (Daily Top {saved_top_k})")

        # ìºì‹œ í‚¤ ìƒì„± (ë‚ ì§œ + ëª¨ë¸ëª… + TopK)
        today_str = pd.Timestamp.now().strftime('%Y-%m-%d')
        cache_key = f"{selected_model_name}_{today_str}_{saved_top_k}"
        
        # ì´ë¯¸ ë¶„ì„í•œ ê²°ê³¼ê°€ ìˆëŠ”ì§€ í™•ì¸
        if cache_key in st.session_state.gemini_insights:
            st.success(f"âš¡ ì €ì¥ëœ ë¶„ì„ ê²°ê³¼ (Date: {today_str})")
            cached_data = st.session_state.gemini_insights[cache_key]
            
            # ì¹´ë“œ í‘œì‹œ (Top K ê°œìˆ˜ë§Œí¼ ì»¬ëŸ¼ ë™ì  ìƒì„± - ë„ˆë¬´ ë§ìœ¼ë©´ 3ê°œì”©)
            st.write(f"**ì¶”ì²œ ì¢…ëª© ({len(cached_data['top_k_items'])}ê°œ)**")
            
            cols = st.columns(min(len(cached_data['top_k_items']), 4)) # ìµœëŒ€ 4ì—´
            for i, item in enumerate(cached_data['top_k_items']):
                col_idx = i % 4
                with cols[col_idx]:
                    st.info(f"**{i+1}ìœ„: {item['Ticker']}**\n\nAI Score: {item['Score']:.4f}")
            
            st.markdown(cached_data['insight'])
            
        else:
            if st.button("ğŸš€ ì¶”ì²œ ì¢…ëª© ë¶„ì„ ì‹¤í–‰ (Gemini)"):
                with st.spinner(f"ìµœì‹  ë°ì´í„° ë¶„ì„ ì¤‘... (Top {saved_top_k})"):
                    model = saved_info['model']
                    scaler = saved_info['scaler']
                    feature_cols = saved_info['feature_cols']
                    full_data = saved_info['full_data']
                    valid_tickers = saved_info['valid_tickers']
                    
                    today_scores = []
                    
                    for ticker in valid_tickers:
                        try:
                            df = full_data[ticker]
                            last_row = df.iloc[[-1]] 
                            last_date = last_row.index[0].strftime('%Y-%m-%d')
                            
                            feats = last_row[feature_cols].values
                            feats_scaled = scaler.transform(feats)
                            score = model.predict(feats_scaled)[0]
                            
                            # ëŒ€í‘œ Feature ê°’ ì¶”ì¶œ (ì„¤ëª…ì„ ìœ„í•´ ì¼ë¶€ë§Œ)
                            # ê°„ë‹¨íˆ ì²« 5ê°œë‚˜ ì£¼ìš” feature ì´ë¦„ ë§¤ì¹­í•´ì„œ ë³´ë‚¼ ìˆ˜ ìˆìŒ
                            feat_dict = {}
                            # Common features across levels
                            if "RSI_14" in last_row.columns: feat_dict["RSI_14"] = f"{last_row['RSI_14'].values[0]:.2f}"
                            elif "RSI" in last_row.columns: feat_dict["RSI"] = f"{last_row['RSI'].values[0]:.2f}" # For Light mode
                            
                            if "ROC_20" in last_row.columns: feat_dict["ROC_20 (Momentum)"] = f"{last_row['ROC_20'].values[0]:.2%}"
                            elif "Momentum_1M" in last_row.columns: feat_dict["Momentum_1M"] = f"{last_row['Momentum_1M'].values[0]:.2%}" # For Light mode
                            
                            if "MA_Dist_20" in last_row.columns: feat_dict["MA_Dist_20"] = f"{last_row['MA_Dist_20'].values[0]:.4f}"
                            elif "Disparity_20" in last_row.columns: feat_dict["Disparity_20"] = f"{last_row['Disparity_20'].values[0]:.4f}" # For Light mode
                            
                            if "Vol_20" in last_row.columns: feat_dict["Vol_20"] = f"{last_row['Vol_20'].values[0]:.4f}"
                            elif "Volatility" in last_row.columns: feat_dict["Volatility"] = f"{last_row['Volatility'].values[0]:.4f}" # For Light mode
                            
                            if not feat_dict: # Rich ëª¨ë“œ ë“±ìœ¼ë¡œ ì´ë¦„ì´ ë‹¤ë¥¼ ê²½ìš° ëŒ€ë¹„ ì•ˆì „ì¥ì¹˜
                                feat_dict = {"Score": f"{score:.4f}"}

                            today_scores.append({
                                "Ticker": ticker,
                                "Score": score,
                                "Date": last_date,
                                "Features": feat_dict
                            })
                        except Exception as e:
                            # st.warning(f"Error processing {ticker} for daily pick: {e}")
                            pass
                    
                    # Top K ì„ ì •
                    today_scores.sort(key=lambda x: x['Score'], reverse=True)
                    top_k_items = today_scores[:saved_top_k]
                    
                    if top_k_items:
                        # Gemini í”„ë¡¬í”„íŠ¸
                        prompt_context = f"Model Type: {selected_model_name}\nTarget Strategy: Buy Top {saved_top_k} scores daily.\n\nTop {saved_top_k} Recommended Stocks:\n"
                        for i, item in enumerate(top_k_items):
                            prompt_context += f"{i+1}. {item['Ticker']} (Score: {item['Score']:.4f})\n   - Indicators: {item['Features']}\n"
                        prompt_context += "\nAct as a Quantitative Analyst. Explain WHY the model likely selected these stocks based on the provided indicators. Focus on the quantitative rationale. Write in Korean."
                        
                        try:
                            # API Key Rotation ì ìš©
                            insight_text = generate_content_with_rotation(prompt_context, model_name="gemini-3-flash-preview")
                            
                            # ê²°ê³¼ ìºì‹±
                            st.session_state.gemini_insights[cache_key] = {
                                "top_k_items": top_k_items,
                                "insight": insight_text
                            }
                            st.rerun()
                            
                        except Exception as e:
                            st.error(f"Gemini ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
                    else:
                        st.warning("ë°ì´í„° ë¶€ì¡±ìœ¼ë¡œ ì˜ˆì¸¡í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

elif selection == "âš–ï¸ í¬íŠ¸í´ë¦¬ì˜¤ ìµœì í™”":
    st.title("âš–ï¸ í¬íŠ¸í´ë¦¬ì˜¤ ìµœì í™” (Portfolio Optimizer)")
    st.caption("í˜„ëŒ€ í¬íŠ¸í´ë¦¬ì˜¤ ì´ë¡ (MPT)ì— ê¸°ë°˜í•˜ì—¬ ìµœì ì˜ ìì‚° ë°°ë¶„ ë¹„ìœ¨ì„ ì œì•ˆí•©ë‹ˆë‹¤.")

    # 1. ì‚¬ì´ë“œë°” ì„¤ì •
    with st.sidebar:
        st.header("âš™ï¸ ìµœì í™” ì„¤ì •")
        tickers_string = st.text_area(
            "í¬íŠ¸í´ë¦¬ì˜¤ êµ¬ì„± ì¢…ëª© (ì‰¼í‘œ êµ¬ë¶„)", 
            value="AAPL, MSFT, GOOGL, AMZN, TSLA, SPY, GLD, TLT",
            height=100
        )
        
        col1, col2 = st.columns(2)
        with col1:
            start_date_opt = st.date_input("ë¶„ì„ ì‹œì‘ì¼", pd.to_datetime("2020-01-01"))
        with col2:
            end_date_opt = st.date_input("ë¶„ì„ ì¢…ë£Œì¼", pd.to_datetime("today"))
            
        risk_free_rate = st.number_input("ë¬´ìœ„í—˜ ì´ììœ¨ (%)", value=3.5, step=0.1) / 100

    # 2. ë°ì´í„° ë‹¤ìš´ë¡œë“œ ë° ì²˜ë¦¬
    st.info("ğŸ’¡ **Efficient Frontier (íš¨ìœ¨ì  íˆ¬ìì„ )**: ë™ì¼í•œ ìœ„í—˜ ìˆ˜ì¤€ì—ì„œ ìµœëŒ€ ìˆ˜ìµì„ ë‚´ê±°ë‚˜, ë™ì¼í•œ ê¸°ëŒ€ ìˆ˜ìµì—ì„œ ìµœì†Œ ìœ„í—˜ì„ ê°–ëŠ” í¬íŠ¸í´ë¦¬ì˜¤ì˜ ì§‘í•©ì…ë‹ˆë‹¤.")
    
    if st.button("ğŸš€ í¬íŠ¸í´ë¦¬ì˜¤ ìµœì í™” ì‹¤í–‰"):
        tickers = [t.strip().upper() for t in tickers_string.split(',') if t.strip()]
        
        if len(tickers) < 2:
            st.warning("ìµœì†Œ 2ê°œ ì´ìƒì˜ ì¢…ëª©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            st.stop()
            
        with st.spinner("ë°ì´í„° ìˆ˜ì§‘ ë° ìµœì í™” ê³„ì‚° ì¤‘..."):
            # ë°ì´í„° ìˆ˜ì§‘
            data = pd.DataFrame()
            valid_tickers = []
            
            for t in tickers:
                try:
                    df = yf.download(t, start=start_date_opt, end=end_date_opt, progress=False)
                    if isinstance(df.columns, pd.MultiIndex):
                        df.columns = df.columns.get_level_values(0)
                        
                    if 'Adj Close' in df.columns:
                        series = df['Adj Close']
                    elif 'Close' in df.columns:
                        series = df['Close']
                    else:
                        continue
                        
                    data[t] = series
                    valid_tickers.append(t)
                except Exception as e:
                    pass
            
            if data.empty or len(valid_tickers) < 2:
                st.error("ìœ íš¨í•œ ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì¢…ëª© ì½”ë“œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
                st.stop()
                
            # ê²°ì¸¡ì¹˜ ì²˜ë¦¬
            data = data.dropna()
            
            # ìˆ˜ìµë¥  ê³„ì‚°
            returns = data.pct_change().dropna()
            mean_returns = returns.mean() * 252 # ì—°ê°„ ê¸°ëŒ€ ìˆ˜ìµë¥ 
            cov_matrix = returns.cov() * 252 # ì—°ê°„ ê³µë¶„ì‚°
            
            # ---------------------------------------------------------
            # í¬íŠ¸í´ë¦¬ì˜¤ ìµœì í™” í•¨ìˆ˜ (Scipy)
            # ---------------------------------------------------------
            def portfolio_annualised_performance(weights, mean_returns, cov_matrix):
                returns = np.sum(mean_returns * weights)
                std = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))
                return std, returns

            def neg_sharpe_ratio(weights, mean_returns, cov_matrix, risk_free_rate):
                p_var, p_ret = portfolio_annualised_performance(weights, mean_returns, cov_matrix)
                return -(p_ret - risk_free_rate) / p_var

            # ì œì•½ ì¡°ê±´
            constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})
            bounds = tuple((0.0, 1.0) for asset in range(len(valid_tickers)))
            
            # ì´ˆê¸°ê°’ (ê· ë“± ë°°ë¶„)
            num_assets = len(valid_tickers)
            init_guess = num_assets * [1. / num_assets,]
            
            # ìµœì í™” ì‹¤í–‰
            opt_result = sco.minimize(
                neg_sharpe_ratio, 
                init_guess, 
                args=(mean_returns, cov_matrix, risk_free_rate), 
                method='SLSQP', 
                bounds=bounds, 
                constraints=constraints
            )
            
            max_sharpe_weights = opt_result['x']
            max_sharpe_std, max_sharpe_ret = portfolio_annualised_performance(max_sharpe_weights, mean_returns, cov_matrix)
            max_sharpe_sharpe = (max_sharpe_ret - risk_free_rate) / max_sharpe_std
            
            # ---------------------------------------------------------
            # ê²°ê³¼ ì‹œê°í™”
            # ---------------------------------------------------------
            
            # 1. íŒŒì´ ì°¨íŠ¸ (ìµœì  ë¹„ì¤‘)
            st.divider()
            
            weights_df = pd.DataFrame({
                "Ticker": valid_tickers,
                "Weight": max_sharpe_weights
            })
            weights_df = weights_df[weights_df['Weight'] > 0.0001] # 0% ì œì™¸
            weights_df['Weight_Pct'] = (weights_df['Weight'] * 100).round(2)
            weights_df = weights_df.sort_values(by="Weight", ascending=False)
            
            c1, c2 = st.columns([1, 1])
            
            with c1:
                st.subheader("ğŸ¯ ìµœì  í¬íŠ¸í´ë¦¬ì˜¤ ë¹„ì¤‘")
                st.caption(f"Max Sharpe Ratio: {max_sharpe_sharpe:.4f}")
                
                fig_pie = px.pie(
                    weights_df, 
                    values='Weight', 
                    names='Ticker', 
                    title='Optimal Asset Allocation',
                    hole=0.4
                )
                fig_pie.update_traces(textposition='inside', textinfo='percent+label')
                st.plotly_chart(fig_pie, use_container_width=True)
                
            with c2:
                st.subheader("ğŸ“Š ì˜ˆìƒ ì„±ê³¼ (ì—°ê°„)")
                st.metric("ê¸°ëŒ€ ìˆ˜ìµë¥  (Annual Return)", f"{max_sharpe_ret:.2%}")
                st.metric("ë³€ë™ì„± (Annual Volatility)", f"{max_sharpe_std:.2%}")
                st.metric("ìƒ¤í”„ ë¹„ìœ¨ (Sharpe Ratio)", f"{max_sharpe_sharpe:.4f}")
                
                st.markdown("#### ë³´ìœ  ë¹„ì¤‘ ìƒì„¸")
                st.dataframe(weights_df[['Ticker', 'Weight_Pct']].style.format({"Weight_Pct": "{:.2f}%"}), hide_index=True)

            # 2. íš¨ìœ¨ì  íˆ¬ìì„  ì°¨íŠ¸ (ì‹œë®¬ë ˆì´ì…˜)
            st.subheader("ğŸ“ˆ íš¨ìœ¨ì  íˆ¬ìì„  (Efficient Frontier)")
            
            with st.spinner("ì‹œë®¬ë ˆì´ì…˜ ì°¨íŠ¸ ìƒì„± ì¤‘..."):
                num_portfolios = 5000
                results = np.zeros((3, num_portfolios))
                
                for i in range(num_portfolios):
                    weights = np.random.random(num_assets)
                    weights /= np.sum(weights)
                    
                    p_std, p_ret = portfolio_annualised_performance(weights, mean_returns, cov_matrix)
                    results[0,i] = p_std
                    results[1,i] = p_ret
                    results[2,i] = (p_ret - risk_free_rate) / p_std
                
                sim_df = pd.DataFrame({
                    "Volatility": results[0,:],
                    "Return": results[1,:],
                    "Sharpe": results[2,:]
                })
                
                fig_ef = px.scatter(
                    sim_df, x="Volatility", y="Return", color="Sharpe",
                    title="Efficient Frontier Simulation (5,000 Portfolios)",
                    color_continuous_scale='Viridis',
                    labels={"Volatility": "ë¦¬ìŠ¤í¬ (í‘œì¤€í¸ì°¨)", "Return": "ê¸°ëŒ€ ìˆ˜ìµë¥ "}
                )
                
                # ìµœì ì  í‘œì‹œ
                fig_ef.add_scatter(
                    x=[max_sharpe_std], y=[max_sharpe_ret], 
                    mode='markers+text', 
                    marker=dict(color='red', size=15, symbol='star'),
                    name='Max Sharpe Portfolio',
                    text=['â˜… Max Sharpe'], textposition="top left"
                )
                
                st.plotly_chart(fig_ef, use_container_width=True)

elif selection == "ğŸ” ê¸°ìˆ ì  íŒ¨í„´ ìŠ¤ìºë„ˆ":
    st.title("ğŸ” ê¸°ìˆ ì  íŒ¨í„´ ìŠ¤ìºë„ˆ (Technical Pattern Scanner)")
    st.caption("ì „ì²´ ì‹œì¥ì„ ìŠ¤ìº”í•˜ì—¬ 'ì§€ê¸ˆ ë‹¹ì¥' ì˜ë¯¸ ìˆëŠ” ì°¨íŠ¸ íŒ¨í„´ì´ ë°œìƒí•œ ì¢…ëª©ì„ í¬ì°©í•©ë‹ˆë‹¤.")

    # 1. ìŠ¤ìº” ëŒ€ìƒ ì„¤ì •
    with st.expander("ğŸ“¡ ìŠ¤ìº” ì„¤ì • (Universe)", expanded=True):
        universe_preset = st.selectbox(
            "ìŠ¤ìº” ëŒ€ìƒ ê·¸ë£¹ ì„ íƒ",
            ["NASDAQ Top 30 (Big Tech)", "Dow Jones 30 (Blue Chips)", "S&P 100 (Large Cap)", "S&P 500 (Full)", "NASDAQ 100 (Full)", "ì§ì ‘ ì…ë ¥"]
        )

        scan_tickers = []

        if universe_preset == "ì§ì ‘ ì…ë ¥":
            tickers_input = st.text_input("ì¢…ëª© ì½”ë“œ ì…ë ¥ (ì‰¼í‘œ êµ¬ë¶„)", "AAPL, MSFT, TSLA, NVDA, AMD, INTC, QCOM")
            scan_tickers = [t.strip().upper() for t in tickers_input.split(',') if t.strip()]
        
        elif universe_preset == "S&P 500 (Full)":
            with st.spinner("S&P 500 ì¢…ëª© ë¦¬ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘..."):
                scan_tickers = get_sp500_tickers()
                if not scan_tickers: # Fallback if fetch fails
                     scan_tickers = ["AAPL", "MSFT", "AMZN", "NVDA", "GOOGL"] # Minimal fallback
        
        elif universe_preset == "NASDAQ 100 (Full)":
             with st.spinner("NASDAQ 100 ì¢…ëª© ë¦¬ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘..."):
                scan_tickers = get_nasdaq100_tickers()
                if not scan_tickers:
                    scan_tickers = ["AAPL", "MSFT", "AMZN", "NVDA", "GOOGL"]

        elif universe_preset == "NASDAQ Top 30 (Big Tech)":
            scan_tickers = [
                "AAPL", "MSFT", "NVDA", "GOOGL", "AMZN", "META", "TSLA", "AVGO", "COST", "PEP",
                "CSCO", "NFLX", "AMD", "ADBE", "TMUS", "INTC", "QCOM", "TXN", "AMGN", "HON",
                "AMAT", "INTU", "SBUX", "ADP", "BKNG", "GILD", "ISRG", "MDLZ", "REGN", "VRTX"
            ]
        elif universe_preset == "Dow Jones 30 (Blue Chips)":
            scan_tickers = [
                "MMM", "AXP", "AMGN", "AAPL", "BA", "CAT", "CVX", "CSCO", "KO", "DIS", 
                "DOW", "GS", "HD", "HON", "IBM", "INTC", "JNJ", "JPM", "MCD", "MRK", 
                "MSFT", "NKE", "PG", "CRM", "TRV", "UNH", "VZ", "V", "WMT", "WBA" # WBA is replaced by AMZN in DJIA recently but keep list simple for now or update
            ]
             # Note: Dow components change. 
        elif universe_preset == "S&P 100 (Large Cap)":
            # Sample list
            scan_tickers = ["AAPL", "MSFT", "AMZN", "NVDA", "GOOGL", "META", "TSLA", "BRK-B", "LLY", "V", "TSM", "UNH", "XOM", "JPM"] 
            st.info("Demo: ì†ë„ë¥¼ ìœ„í•´ ì£¼ìš” 14ê°œ ì¢…ëª©ë§Œ ìŠ¤ìº”í•©ë‹ˆë‹¤.")
            
        st.write(f"ì´ {len(scan_tickers)}ê°œ ì¢…ëª©ì„ ë¶„ì„í•©ë‹ˆë‹¤.")

    # 2. ìŠ¤ìº” ì‹¤í–‰
    if st.button("ğŸ›°ï¸ íŒ¨í„´ ìŠ¤ìº” ì‹œì‘"):
        # Session State ì´ˆê¸°í™”
        if 'scan_results' not in st.session_state:
            st.session_state.scan_results = []
            
        results = []
        
        status_text = st.empty()
        progress_bar = st.progress(0)
        
        # ë°ì´í„° ì¼ê´„ ë‹¤ìš´ë¡œë“œ (ì†ë„ ê°œì„ )
        status_text.text("ë°ì´í„° ì¼ê´„ ë‹¤ìš´ë¡œë“œ ì¤‘...")
        
        # ê¸°ê°„: ë„‰ë„‰íˆ 120ì¼ (MA60 ê³„ì‚°ìš©)
        start_date_scan = pd.to_datetime("today") - pd.Timedelta(days=200)
        
        try:
            # yfinance batch download
            # threads=True is default
            raw_data = yf.download(scan_tickers, start=start_date_scan, group_by='ticker', progress=False)
        except Exception as e:
            st.error(f"ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
            st.stop()
            
        status_text.text("íŒ¨í„´ ë¶„ì„ ì¤‘...")
        
        for i, ticker in enumerate(scan_tickers):
            try:
                # ë°ì´í„° ì¶”ì¶œ
                if len(scan_tickers) == 1:
                    df = raw_data
                else:
                    df = raw_data[ticker]
                
                # MultiIndex ì»¬ëŸ¼ ì •ë¦¬
                if isinstance(df.columns, pd.MultiIndex):
                    df.columns = df.columns.get_level_values(0)
                
                # ìœ íš¨ì„± ê²€ì‚¬
                if df.empty or 'Close' not in df.columns:
                    continue
                    
                df = df.dropna(subset=['Close'])
                if len(df) < 60: # ìµœì†Œ ë°ì´í„° ìš”êµ¬ëŸ‰
                    continue
                
                # ---------------- [íŒ¨í„´ ì¸ì‹ ì—”ì§„] ----------------
                detected_patterns = []
                detailed_info = [] # ìƒì„¸ ì •ë³´ (RSI ê°’ ë“±)
                
                # ìµœì‹  ë°ì´í„°
                curr_price = df['Close'].iloc[-1]
                prev_price = df['Close'].iloc[-2]
                
                # 1. ì´í‰ì„  (Golden/Death Cross)
                ma20 = df['Close'].rolling(20).mean()
                ma60 = df['Close'].rolling(60).mean()
                
                curr_ma20 = ma20.iloc[-1]
                curr_ma60 = ma60.iloc[-1]
                prev_ma20 = ma20.iloc[-2]
                prev_ma60 = ma60.iloc[-2]
                
                # ê³¨ë“  í¬ë¡œìŠ¤: ì–´ì œëŠ” 20 < 60 ì´ì—ˆëŠ”ë° ì˜¤ëŠ˜ 20 > 60
                if prev_ma20 < prev_ma60 and curr_ma20 > curr_ma60:
                    detected_patterns.append("âœ¨ Golden Cross (ë§¤ìˆ˜ ì‹ í˜¸)")
                
                # ë°ë“œ í¬ë¡œìŠ¤
                if prev_ma20 > prev_ma60 and curr_ma20 < curr_ma60:
                    detected_patterns.append("ğŸ’€ Death Cross (ë§¤ë„ ì‹ í˜¸)")
                    
                # 2. RSI (ê³¼ë§¤ìˆ˜/ê³¼ë§¤ë„)
                delta = df['Close'].diff()
                gain = (delta.where(delta > 0, 0)).rolling(14).mean()
                loss = (-delta.where(delta < 0, 0)).rolling(14).mean()
                rs = gain / loss
                rsi = 100 - (100 / (1 + rs))
                curr_rsi = rsi.iloc[-1]
                
                if curr_rsi < 30:
                    detected_patterns.append("ğŸŸ¢ RSI ê³¼ë§¤ë„ (ë°˜ë“± ê¸°ëŒ€)")
                    detailed_info.append(f"RSI: {curr_rsi:.1f}")
                elif curr_rsi > 70:
                    detected_patterns.append("ğŸ”´ RSI ê³¼ë§¤ìˆ˜ (ì¡°ì • ì£¼ì˜)")
                    detailed_info.append(f"RSI: {curr_rsi:.1f}")
                    
                # 3. ë³¼ë¦°ì € ë°´ë“œ (ëŒíŒŒ)
                std = df['Close'].rolling(20).std()
                upper = ma20 + (std * 2)
                lower = ma20 - (std * 2)
                
                curr_upper = upper.iloc[-1]
                curr_lower = lower.iloc[-1]
                
                if curr_price < curr_lower:
                    detected_patterns.append("ğŸ“‰ ë³¼ë¦°ì € í•˜ë‹¨ ëŒíŒŒ (ê³¼ë§¤ë„)")
                elif curr_price > curr_upper:
                    detected_patterns.append("ğŸ“ˆ ë³¼ë¦°ì € ìƒë‹¨ ëŒíŒŒ (ê°•í•œ ìƒìŠ¹ì„¸)")
                
                # ------------------------------------------------
                
                if detected_patterns:
                    # ê²°ê³¼ ì €ì¥
                    results.append({
                        "Ticker": ticker,
                        "Price": f"${curr_price:.2f}",
                        "Change": f"{(curr_price - prev_price)/prev_price:.2%}",
                        "Patterns": detected_patterns,
                        "Details": detailed_info
                    })
                    
            except Exception as e:
                pass
            
            progress_bar.progress((i + 1) / len(scan_tickers))
            
        status_text.empty()
        progress_bar.empty()
        
        # ê²°ê³¼ë¥¼ Session Stateì— ì €ì¥
        st.session_state.scan_results = results

    # 3. ê²°ê³¼ í‘œì‹œ (Session State ì‚¬ìš©)
    if 'scan_results' in st.session_state and st.session_state.scan_results:
        results = st.session_state.scan_results
        
        st.divider()
        # ---------------------------------------------------------
        # í•„í„°ë§ UI
        # ---------------------------------------------------------
        # 1. ëª¨ë“  ë°œê²¬ëœ íŒ¨í„´ ìˆ˜ì§‘ (ì¤‘ë³µ ì œê±° & ë‹¨ìˆœí™”ëœ íƒœê·¸ ì‚¬ìš©)
        all_patterns = set()
        for r in results:
            for p in r['Patterns']:
                all_patterns.add(p)
        
        sorted_patterns = sorted(list(all_patterns))
        
        col_f1, col_f2 = st.columns([3, 1])
        with col_f1:
            selected_filters = st.multiselect(
                "ğŸ” ì›í•˜ëŠ” íŒ¨í„´ë§Œ ê³¨ë¼ë³´ê¸° (ë³µìˆ˜ ì„ íƒ ê°€ëŠ¥)", 
                options=sorted_patterns,
                placeholder="ëª¨ë“  ê²°ê³¼ ë³´ê¸°"
            )
            
            # í•„í„° ëª¨ë“œ ì„ íƒ (Radio Button) - ê°€ë¡œë¡œ ë°°ì¹˜
            filter_mode = st.radio(
                "ì¡°ê±´ ë§¤ì¹­ ë°©ì‹", 
                ["í•˜ë‚˜ë¼ë„ í¬í•¨ (OR)", "ëª¨ë‘ í¬í•¨ (AND)"],
                horizontal=True,
                help="OR: ì„ íƒí•œ ì¡°ê±´ ì¤‘ í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´ í‘œì‹œí•©ë‹ˆë‹¤.\nAND: ì„ íƒí•œ ì¡°ê±´ì„ ëª¨ë‘ ë§Œì¡±í•´ì•¼ í‘œì‹œí•©ë‹ˆë‹¤."
            )
            
        # 2. í•„í„°ë§ ë¡œì§
        filtered_results = []
        if not selected_filters:
            filtered_results = results
        else:
            for r in results:
                result_patterns = set(r['Patterns'])
                filter_patterns = set(selected_filters)
                
                if "OR" in filter_mode:
                    # OR: êµì§‘í•©ì´ ìˆìœ¼ë©´ True
                    if result_patterns.intersection(filter_patterns):
                        filtered_results.append(r)
                else:
                    # AND: í•„í„°ê°€ ê²°ê³¼ì˜ ë¶€ë¶„ì§‘í•©ì´ì–´ì•¼ í•¨ (í•„í„° ì¡°ê±´ì„ ëª¨ë‘ ë§Œì¡±)
                    if filter_patterns.issubset(result_patterns):
                        filtered_results.append(r)
        
        with col_f2:
            st.metric("ê²€ìƒ‰ ê²°ê³¼", f"{len(filtered_results)} / {len(results)}")

        if filtered_results:
            st.success(f"ì¡°ê±´ì— ë§ëŠ” ì¢…ëª© {len(filtered_results)}ê°œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤!")
            
            for item in filtered_results:
                with st.container():
                    c1, c2, c3 = st.columns([1, 1.5, 3])
                    c1.subheader(item['Ticker'])
                    c2.metric("í˜„ì¬ê°€", item['Price'], item['Change'])
                    
                    with c3:
                        st.write("**ë°œê²¬ëœ íŒ¨í„´:**")
                        # íŒ¨í„´ ë±ƒì§€
                        for pat in item['Patterns']:
                            if "ë§¤ìˆ˜" in pat or "ë°˜ë“±" in pat or "Golden" in pat:
                                st.success(pat)
                            elif "ë§¤ë„" in pat or "ì£¼ì˜" in pat or "Death" in pat:
                                st.error(pat)
                            else:
                                st.info(pat)
                        # ìƒì„¸ ì •ë³´ (RSI ê°’ ë“±)
                        if item.get('Details'):
                            st.caption(", ".join(item['Details']))
                    st.divider()
        else:
            st.warning("ì„ íƒí•œ í•„í„°ì— ë§ëŠ” ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

    elif 'scan_results' in st.session_state and not st.session_state.scan_results:
         st.info("í˜„ì¬ ê¸°ì¤€ íŠ¹ì´ íŒ¨í„´(ê³¨ë“ í¬ë¡œìŠ¤, ê³¼ë§¤ìˆ˜/ê³¼ë§¤ë„ ë“±)ì´ ë°œê²¬ëœ ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")


# -----------------------------------------------------------------------------
# ğŸ” ETF êµ¬ì„± ì¢…ëª© ê²€ìƒ‰ (Reverse Search)
# -----------------------------------------------------------------------------
elif selection == "ğŸ” ETF êµ¬ì„± ì¢…ëª© ê²€ìƒ‰":
    st.title("ğŸ” ETF êµ¬ì„± ì¢…ëª© ê²€ìƒ‰ (Reverse Search)")
    st.caption("íŠ¹ì • ì¢…ëª©ì„ ë‹´ê³  ìˆëŠ” ETFë¥¼ ê²€ìƒ‰í•˜ê³ , ë¹„ì¤‘ ìˆœìœ¼ë¡œ ì •ë ¬í•©ë‹ˆë‹¤. (KRX ì‹¤ì‹œê°„ ë°ì´í„° ê¸°ë°˜)")

    import FinanceDataReader as fdr

    # 1. ìœ íš¨í•œ ë°ì´í„°ê°€ ìˆëŠ” ìµœì‹  ì˜ì—…ì¼ êµ¬í•˜ê¸°
    # (ì£¼ì˜: fdrì€ ë³„ë„ ë‚ ì§œ ì²´í¬ ì—†ì´ ìµœì‹  ë¦¬ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜¤ë¯€ë¡œ, ì—¬ê¸°ì„œëŠ” ë‹¨ìˆœíˆ ì˜¤ëŠ˜ ë‚ ì§œ ë˜ëŠ” ì•ˆì „í•œ í‰ì¼ì„ ë°˜í™˜)
    @st.cache_data(ttl=3600*12) 
    def get_latest_biz_date():
        # ETF PDF ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ë•ŒëŠ” ë‚ ì§œê°€ ì¤‘ìš”í•˜ë¯€ë¡œ, í‰ì¼ì¸ì§€ ì²´í¬
        curr = datetime.now()
        # ë§Œì•½ ì£¼ë§ì´ë©´ ê¸ˆìš”ì¼ë¡œ ì´ë™
        while curr.weekday() > 4:
            curr -= timedelta(days=1)
        return curr.strftime("%Y%m%d")

    target_date = get_latest_biz_date()
    st.info(f"ğŸ“… ë°ì´í„° ê¸°ì¤€ì¼: **{target_date[:4]}-{target_date[4:6]}-{target_date[6:]}** (KRX)")

    # 2. ë°ì´í„° ìˆ˜ì§‘ ë° ìºì‹±
    @st.cache_data(ttl=3600*24, show_spinner=False) # 24ì‹œê°„ ìºì‹œ
    def get_all_etf_data(date):
        """
        ëª¨ë“  ETFì˜ êµ¬ì„± ì¢…ëª©(PDF) ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ì—¬ Dictionary í˜•íƒœë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
        Key: Ticker, Value: Data (Name, PDF_DataFrame)
        """
        # A. ETF ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸° (pykrx ëŒ€ì‹  fdr ì‚¬ìš© - ì¸ì½”ë”© ì´ìŠˆ ìš°íšŒ)
        tickers = []
        try:
            # KRX ETF ë¦¬ìŠ¤íŠ¸ (Symbol, Name ë“± í¬í•¨)
            etf_list_df = fdr.StockListing('ETF/KR')
            tickers = etf_list_df['Symbol'].tolist()
        except Exception as e:
            # st.error(f"ETF ë¦¬ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ (FDR): {e}")
            pass
        
        # Fallback: ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨ ì‹œ ì£¼ìš” ETF í•˜ë“œì½”ë”©
        if not tickers:
            tickers = [
                "069500", # KODEX 200
                "371460", # TIGER ì°¨ì´ë‚˜ì „ê¸°ì°¨SOLACTIVE
                "122630", # KODEX ë ˆë²„ë¦¬ì§€
                "252670", # KODEX 200ì„ ë¬¼ì¸ë²„ìŠ¤2X
                "233740", # KODEX ì½”ìŠ¤ë‹¥150ë ˆë²„ë¦¬ì§€
                "251340", # KODEX ì½”ìŠ¤ë‹¥150ì„ ë¬¼ì¸ë²„ìŠ¤
                "102110", # TIGER 200
                "278530", # KODEX 200TR
                "278540", # TIGER 200TR
                "360750", # TIGER ë¯¸êµ­S&P500
                "360200", # TIGER ë¯¸êµ­ë‚˜ìŠ¤ë‹¥100
            ]
            st.warning("âš ï¸ ETF ì „ì²´ ë¦¬ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í•´ ì£¼ìš” 11ê°œ ETFë§Œ ìŠ¤ìº”í•©ë‹ˆë‹¤.")
            # st.success(f"ì´ {len(tickers)}ê°œì˜ ETF ë¦¬ìŠ¤íŠ¸ë¥¼ í™•ë³´í–ˆìŠµë‹ˆë‹¤.")
            pass
            
        etf_data = {}
        error_count = 0


        
        # ì§„í–‰ë¥  í‘œì‹œ (ìµœì´ˆ ì‹¤í–‰ ì‹œì—ë§Œ ë³´ì„)
        progress_text = "KRXì—ì„œ ëª¨ë“  ETF ë°ì´í„°(PDF)ë¥¼ ìˆ˜ì§‘ ì¤‘ì…ë‹ˆë‹¤... (ìµœì´ˆ 1íšŒ ì‹¤í–‰ ì‹œ 3~5ë¶„ ì†Œìš”)"
        my_bar = st.progress(0, text=progress_text)
        
        total = len(tickers)
        
        # FDRì—ì„œ ê°€ì ¸ì˜¨ ì´ë¦„ ë§¤í•‘ (Name Column í™•ì¸ í•„ìš”, ë³´í†µ 'Name')
        name_map = {}
        if 'Name' in etf_list_df.columns:
            name_map = etf_list_df.set_index('Symbol')['Name'].to_dict()
        
        total = len(tickers)
        
        
        last_error = None
        
        for i, ticker in enumerate(tickers):
            pdf = None
            try:
                # 1. pykrx ì‹œë„
                try:
                    pdf = stock.get_etf_portfolio_deposit_file(ticker, date)
                except:
                    pdf = None

                # 2. ì‹¤íŒ¨ ì‹œ Naver Finance í¸ë²• í¬ë¡¤ë§ (html5lib/lxml í•„ìš”)
                if pdf is None or pdf.empty:
                    try:
                        url = f"https://finance.naver.com/item/sise_pdf.naver?code={ticker}"
                        # ë°˜ë“œì‹œ requestsë¥¼ ì‚¬ìš©í•´ verify=False ì ìš© (pd.read_htmlì€ ë‚´ë¶€ì ìœ¼ë¡œ urllib ì‚¬ìš©ì‹œ SSL ê²€ì¦ í•  ìˆ˜ ìˆìŒ)
                        # User-Agent ì¶”ê°€ (Bot ì°¨ë‹¨ ë°©ì§€)
                        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'}
                        resp = requests.get(url, headers=headers, verify=False, timeout=5)
                        
                        # ì¸ì½”ë”© ì„¤ì • (ë„¤ì´ë²„ëŠ” EUC-KR)
                        dfs = pd.read_html(resp.text) 
                        
                        if dfs:
                            pdf = dfs[0]
                            # ì»¬ëŸ¼ ë³´ì • (Naver Data Cleaning)
                            # ë³´í†µ ì»¬ëŸ¼: [êµ¬ì„±ì¢…ëª©(êµ¬ì„±ìì‚°), ìˆ˜ëŸ‰, ê¸ˆì•¡, ë¹„ì¤‘(%), í‰ê°€ì†ìµ, í˜„ì¬ê°€, ë“±ë½, ì „ì¼ë¹„]
                            # pykrx í¬ë§·ê³¼ í˜¸í™˜ë˜ê²Œ Rename í•„ìš”í•  ìˆ˜ ìˆìŒ.
                            rename_map = {
                                'êµ¬ì„±ì¢…ëª©(êµ¬ì„±ìì‚°)': 'Name',
                                'êµ¬ì„±ì¢…ëª©': 'Name',
                                'ë¹„ì¤‘(%)': 'ë¹„ì¤‘',
                                'í‰ê°€ê¸ˆì•¡': 'ê¸ˆì•¡',
                                'ê¸ˆì•¡': 'ê¸ˆì•¡'
                            }
                            pdf = pdf.rename(columns=rename_map)
                            
                    except Exception as e_nav:
                        if last_error is None:
                            last_error = str(e_nav)
                        pass
                
                # ë°ì´í„° ìœ íš¨ì„± ê²€ì‚¬
                if pdf is not None and not pdf.empty:
                    # FDR Name Map ì‚¬ìš©
                    name = name_map.get(str(ticker), str(ticker))
                    
                    etf_data[ticker] = {
                        "name": name,
                        "pdf": pdf 
                    }
            except Exception as e:
                error_count += 1
            
            # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ (ë„ˆë¬´ ìì£¼í•˜ë©´ ëŠë ¤ì§€ë¯€ë¡œ 5% ë‹¨ìœ„ or 10ê°œ ë‹¨ìœ„)
            if i % 10 == 0:
                my_bar.progress((i + 1) / total, text=f"{progress_text} ({i+1}/{total})")
                
        my_bar.empty()
        
        # Debug Info: ì²«ë²ˆì§¸ ì—ëŸ¬ ë³´ì—¬ì£¼ê¸° (ì‚¬ìš©ì í”¼ë“œë°±ìš©)
        if last_error and not etf_data:
             with st.expander("âš ï¸ ë°ì´í„° ìˆ˜ì§‘ ì—ëŸ¬ ìƒì„¸ (Debug Logs)"):
                st.write(f"Last Error: {last_error}")

        
        if error_count > 0:
            st.warning(f"{error_count}ê°œì˜ ETF ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤ (ìƒì¥íì§€ ë“± ì´ìœ ).")
            
        return etf_data

    # ë°ì´í„° ë¡œë”© Trigger
    with st.spinner("ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ë™ê¸°í™” ì¤‘ì…ë‹ˆë‹¤... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”."):
        all_etf_data = get_all_etf_data(target_date)

    # 3. ê²€ìƒ‰ UI
    st.divider()
    search_query = st.text_input("ê²€ìƒ‰í•  ì¢…ëª©ëª…ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ì‚¼ì„±ì „ì, NAVER)", placeholder="ì¢…ëª©ëª… ì…ë ¥ í›„ Enter").strip()

    if search_query:
        # A. ê²€ìƒ‰ ë¡œì§
        found_etfs = []
        
        # ì‚¬ìš©ìê°€ ì…ë ¥í•œ ê²Œ í‹°ì»¤ì¸ì§€ ì´ë¦„ì¸ì§€ ëª¨ë¦„ -> ì´ë¦„ìœ¼ë¡œ ë§¤ì¹­ ì‹œë„
        # pykrxì˜ PDF ë°ì´í„°ì—ëŠ” ì¢…ëª©ì½”ë“œê°€ ì¸ë±ìŠ¤ì´ê³ , ì¢…ëª©ëª…ì€ ì—†ì„ ìˆ˜ ìˆìŒ.
        # ë”°ë¼ì„œ "ì‚¼ì„±ì „ì"ë¥¼ "005930"ìœ¼ë¡œ ë³€í™˜í•˜ê±°ë‚˜, PDF ë‚´ì— ì¢…ëª©ëª…ì´ ìˆëŠ”ì§€ í™•ì¸í•´ì•¼ í•¨.
        # get_etf_portfolio_deposit_file() ê²°ê³¼ëŠ” ë³´í†µ ì¸ë±ìŠ¤=í‹°ì»¤, ì»¬ëŸ¼=[ê³„ì•½ìˆ˜, ê¸ˆì•¡, ë¹„ì¤‘] í˜•íƒœì„. ì¢…ëª©ëª…ì´ ì—†ìŒ.
        # í•´ê²°ì±…:
        # 1. KOSPI/KOSDAQ ì „ ì¢…ëª© ë§ˆìŠ¤í„° ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ì„œ {ì´ë¦„: í‹°ì»¤} ë§¤í•‘ì„ ë§Œë“¦.
        # 2. ì‚¬ìš©ìê°€ ì…ë ¥í•œ "ì‚¼ì„±ì „ì" -> "005930" ë³€í™˜.
        # 3. ê° ETFì˜ PDF ì¸ë±ìŠ¤(í‹°ì»¤)ì— "005930"ì´ ìˆëŠ”ì§€ í™•ì¸.
        
        @st.cache_data
        def get_stock_name_map(date):
            # 1. FDR KRX ì „ì²´ ë¦¬ìŠ¤íŠ¸ ì‹œë„
            name_map = {}
            try:
                df_krx = fdr.StockListing('KRX')
                if not df_krx.empty:
                    name_map = df_krx.set_index('Name')['Symbol'].to_dict()
            except Exception as e:
                pass
            
            # 2. ì‹¤íŒ¨í•˜ê±°ë‚˜ ë¹„ì–´ìˆìœ¼ë©´ KOSPI/KOSDAQ ê°œë³„ ì‹œë„ (Fallback)
            if not name_map:
                try:
                    df_kospi = fdr.StockListing('KOSPI')
                    df_kosdaq = fdr.StockListing('KOSDAQ')
                    if not df_kospi.empty:
                        name_map.update(df_kospi.set_index('Name')['Symbol'].to_dict())
                    if not df_kosdaq.empty:
                        name_map.update(df_kosdaq.set_index('Name')['Symbol'].to_dict())
                except:
                    pass
            # 3. ìµœí›„ì˜ ìˆ˜ë‹¨: ì£¼ìš” ì¢…ëª© í•˜ë“œì½”ë”© (ë„¤íŠ¸ì›Œí¬/íŒŒì‹± ì „ë©´ ì‹¤íŒ¨ ì‹œ ëŒ€ë¹„)
            if not name_map:
                name_map = {
                    "ì‚¼ì„±ì „ì": "005930",
                    "SKí•˜ì´ë‹‰ìŠ¤": "000660",
                    "NAVER": "035420",
                    "ì¹´ì¹´ì˜¤": "035720",
                    "LGì—ë„ˆì§€ì†”ë£¨ì…˜": "373220",
                    "í˜„ëŒ€ì°¨": "005380",
                    "POSCOí™€ë”©ìŠ¤": "005490",
                    "ê¸°ì•„": "000270",
                    "KBê¸ˆìœµ": "105560"
                }
            
            return name_map

        name_map = get_stock_name_map(target_date)
        
        # Debug Info: í™œì„±í™”í•´ì„œ ìƒíƒœ í™•ì¸
        st.warning(f"ğŸ” Debug Info: Loaded {len(name_map)} stocks. " 
                   f"Sample: {list(name_map.keys())[:5] if name_map else 'Empty'}")

        
        # ê²€ìƒ‰ì–´ ë§¤ì¹­ (ì •í™•ì¹˜ & í¬í•¨)
        target_ticker = name_map.get(search_query) # ì •í™•íˆ ì¼ì¹˜
        
        # ì •í™•íˆ ì¼ì¹˜í•˜ì§€ ì•Šìœ¼ë©´ í¬í•¨ ê²€ìƒ‰ (ì²« ë²ˆì§¸ ë°œê²¬ëœ ê²ƒ)
        if not target_ticker:
            candidates = [name for name in name_map.keys() if search_query.upper() in name.upper()]
            if len(candidates) > 0:
                # ì„ íƒì§€ ì œê³µ? ì•„ë‹ˆë©´ ì²«ë²ˆì§¸?
                # UXìƒ ëª¨í˜¸í•˜ë©´ ê°€ì¥ ìœ ì‚¬í•œ ê²ƒ ì„ íƒ or Selectbox
                if len(candidates) == 1:
                    target_ticker = name_map[candidates[0]]
                    st.success(f"'{candidates[0]}' ({target_ticker}) ì¢…ëª©ìœ¼ë¡œ ê²€ìƒ‰í•©ë‹ˆë‹¤.")
                else:
                    st.info(f"ê²€ìƒ‰ì–´ '{search_query}'ì™€ ìœ ì‚¬í•œ ì¢…ëª©: {', '.join(candidates[:5])} ...")
                    selected_name = st.selectbox("ì¢…ëª©ì„ ì„ íƒí•˜ì„¸ìš”:", candidates)
                    target_ticker = name_map[selected_name]
            else:
                st.error("í•´ë‹¹í•˜ëŠ” ì¢…ëª©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                st.stop()
        
        # B. ETF í•„í„°ë§
        result_list = []
        
        # Debug: ë°ì´í„°ê°€ ë¹„ì–´ìˆëŠ”ì§€ í™•ì¸
        if not all_etf_data:
            st.error("ETF ë°ì´í„°ë¥¼ í•˜ë‚˜ë„ ìˆ˜ì§‘í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (KRX/ë„¤ì´ë²„ ì ‘ì† ì‹¤íŒ¨)")
        else:
            # st.info(f"Debug: {len(all_etf_data)}ê°œ ETF ë°ì´í„° ìŠ¤ìº” ì¤‘...")
            pass

        for etf_ticker, data in all_etf_data.items():
            pdf_df = data['pdf']
            found = False
            row = None
            
            # 1. Tickerë¡œ ê²€ìƒ‰ (pykrx ë°ì´í„°ì¸ ê²½ìš° Indexê°€ Ticker)
            if target_ticker in pdf_df.index:
                row = pdf_df.loc[target_ticker]
                found = True
            
            # 2. Tickerê°€ ì»¬ëŸ¼ì— ìˆëŠ”ì§€ í™•ì¸
            elif 'Code' in pdf_df.columns and target_ticker in pdf_df['Code'].values:
                # í•´ë‹¹ ë¡œìš° ì°¾ê¸°
                row = pdf_df[pdf_df['Code'] == target_ticker].iloc[0]
                found = True

            # 3. ì¢…ëª©ëª…ìœ¼ë¡œ ê²€ìƒ‰ (Naver í¬ë¡¤ë§ ë°ì´í„°ì¸ ê²½ìš° Tickerê°€ ì—†ì„ ìˆ˜ ìˆìŒ)
            if not found:
                # ë¬¸ìì—´ ì»¬ëŸ¼ë“¤ ì¤‘ì—ì„œ ì¢…ëª©ëª…ì´ í¬í•¨ëœ í–‰ ì°¾ê¸°
                # search_query: "ì‚¼ì„±ì „ì"
                for col in pdf_df.columns:
                    # ë°ì´í„° íƒ€ì…ì´ ë¬¸ìì—´ì´ê±°ë‚˜ objectì¸ ê²½ìš°
                    if pdf_df[col].dtype == object or pdf_df[col].dtype == str:
                        # ì •í™•íˆ ì¼ì¹˜í•˜ê±°ë‚˜ í¬í•¨ë˜ëŠ”ì§€ í™•ì¸ (ì—¬ê¸°ì„  ì •í™• ì¼ì¹˜ ì„ í˜¸í•˜ë‚˜, ê³µë°± ì´ìŠˆ ë“±ìœ¼ë¡œ í¬í•¨ ì‚¬ìš©)
                        # í•˜ì§€ë§Œ "ì‚¼ì„±" ê²€ìƒ‰ ì‹œ "ì‚¼ì„±ì „ì"ê°€ ê±¸ë¦¬ëŠ”ê±´ ì˜ë„ëœ ë™ì‘.
                        # "ì‚¼ì„±ì „ì" ê²€ìƒ‰ ì‹œ "ì‚¼ì„±ì „ì" í–‰ì„ ì°¾ì•„ì•¼ í•¨.
                        
                        # ì•ˆì „í•œ ì²˜ë¦¬ë¥¼ ìœ„í•´ string ë³€í™˜ í›„ ê²€ìƒ‰
                        matches = pdf_df[pdf_df[col].astype(str).str.contains(search_query, na=False)]
                        if not matches.empty:
                            row = matches.iloc[0]
                            found = True
                            break
            
            if found and row is not None:
                # ì»¬ëŸ¼ëª…ì´ ì¡°ê¸ˆì”© ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë¹„ì¤‘ ì»¬ëŸ¼ ì°¾ê¸°
                weight = 0
                
                # ë‹¤ì–‘í•œ ì»¬ëŸ¼ëª… ì‹œë„
                cols = pdf_df.columns
                weight_col = next((c for c in cols if 'ë¹„ì¤‘' in c), None) # 'ë¹„ì¤‘', 'ë¹„ì¤‘(%)', 'êµ¬ì„±ë¹„ì¤‘' ë“±
                amount_col = next((c for c in cols if 'ê¸ˆì•¡' in c or 'í‰ê°€ì•¡' in c), None) # 'ê¸ˆì•¡', 'í‰ê°€ê¸ˆì•¡'
                
                if weight_col:
                    weight = row[weight_col]
                elif amount_col: 
                    # ê¸ˆì•¡ë§Œ ìˆê³  ë¹„ì¤‘ ì—†ìœ¼ë©´ ì „ì²´ í•© ëŒ€ë¹„ ë¹„ìœ¨ ê³„ì‚°
                    # í•´ë‹¹ ì»¬ëŸ¼ì˜ í•©
                    try:
                        total_amt = pdf_df[amount_col].sum()
                        if total_amt > 0:
                            weight = (row[amount_col] / total_amt) * 100
                    except:
                        pass
                
                # ë¹„ì¤‘ì´ ë¬¸ìì—´ì¸ ê²½ìš° ì²˜ë¦¬ (Naver ë“±)
                if isinstance(weight, str):
                    try:
                        weight = float(weight.replace('%', '').strip())
                    except:
                        pass
                
                result_list.append({
                    "ETF ì½”ë“œ": etf_ticker,
                    "ETFëª…": data['name'],
                    "ì¢…ëª© ë¹„ì¤‘(%)": weight,
                    "ë³´ìœ  ê¸ˆì•¡": row[amount_col] if amount_col else 0
                })

        # C. ê²°ê³¼ ì¶œë ¥
        # C. ê²°ê³¼ ì¶œë ¥
        if result_list:
            df_result = pd.DataFrame(result_list)
            # ë¹„ì¤‘ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
            df_result = df_result.sort_values(by="ì¢…ëª© ë¹„ì¤‘(%)", ascending=False).reset_index(drop=True)
            
            st.success(f"ì´ {len(df_result)}ê°œì˜ ETFê°€ í•´ë‹¹ ì¢…ëª©ì„ í¬í•¨í•˜ê³  ìˆìŠµë‹ˆë‹¤.")
            
            # í…Œì´ë¸”
            st.dataframe(
                df_result.style.format({"ì¢…ëª© ë¹„ì¤‘(%)": "{:.2f}", "ë³´ìœ  ê¸ˆì•¡": "{:,.0f}"}),
                use_container_width=True
            )
            
            # ì°¨íŠ¸ (ìƒìœ„ 5ê°œì¸ì§€, ì‚¬ìš©ì ì„ íƒì¸ì§€) -> ìƒìœ„ 10ê°œ ì‹œê°í™”
            top_n = df_result.head(10)
            fig = px.bar(
                top_n, 
                x="ETFëª…", 
                y="ì¢…ëª© ë¹„ì¤‘(%)", 
                title=f"'{search_query}' ë¹„ì¤‘ì´ ë†’ì€ ETF Top 10",
                color="ì¢…ëª© ë¹„ì¤‘(%)",
                text="ì¢…ëª© ë¹„ì¤‘(%)"
            )
            fig.update_traces(texttemplate='%{text:.2f}%', textposition='outside')
            st.plotly_chart(fig, use_container_width=True)
            
        else:
            st.warning("í•´ë‹¹ ì¢…ëª©ì„ í¬í•¨í•˜ëŠ” ETFê°€ ì—†ìŠµë‹ˆë‹¤.")
